{
  "agent_name": "es_agent_v2",
  "system_prompt": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "tools": [
    "search"
  ],
  "messages": [
    {
      "parts": [
        {
          "content": "Can you elaborate on how attributes are normalized when a non-OpenTelemetry-compliant document is detected?",
          "timestamp": "2025-10-03T06:00:26.750484+00:00",
          "part_kind": "user-prompt"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "args": "{\"query\":\"attributes normalized non-OpenTelemetry-compliant document\"}",
          "tool_call_id": "call_Xr0I1V0wtl0F4yKAoy55vxFj",
          "part_kind": "tool-call"
        }
      ],
      "usage": {
        "input_tokens": 221,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 21,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T06:00:26+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "tool_calls"
      },
      "provider_response_id": "chatcmpl-CMT86mM833m3T2wxZglsgt6COjQbl",
      "finish_reason": "tool_call"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "content": [
            {
              "navigation_title": "Normalize for Stream",
              "applies_to": {
                "stack": "preview 9.1"
              },
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/normalize-for-stream-processor.html"
              ],
              "content": "# Normalize-for-Stream processor [normalize-for-stream-processor]\n\n\nDetects whether a document is OpenTelemetry-compliant and if not -\nnormalizes it as described below. If used in combination with the OTel-related\nmappings such as the ones defined in `logs-otel@template`, the resulting\ndocument can be queried seamlessly by clients that expect either [ECS](https://www.elastic.co/guide/en/ecs/current/index.html) or OpenTelemetry-[Semantic-Conventions](https://github.com/open-telemetry/semantic-conventions) formats.\n\n::::{note}\nThis processor is in tech preview and is not available in our serverless offering.\n::::\n\n## Detecting OpenTelemetry compliance\n\nThe processor detects OpenTelemetry compliance by checking the following fields:\n* `resource` exists as a key and the value is a map\n* `resource` either doesn't contain an `attributes` field, or contains an `attributes` field of type map\n* `scope` is either missing or a map\n* `attributes` is either missing or a map\n* `body` is either missing or a map\n* `body` either doesn't contain a `text` field, or contains a `text` field of type `String`\n* `body` either doesn't contain a `structured` field, or contains a `structured` field that is not of type `String`\n\nIf all of these conditions are met, the document is considered OpenTelemetry-compliant and is not modified by the processor.\n\n## Normalization\n\nIf the document is not OpenTelemetry-compliant, the processor normalizes it as follows:\n* Specific ECS fields are renamed to have their corresponding OpenTelemetry Semantic Conventions attribute names. These include the following:\n\n  | ECS Field   | Semantic Conventions Attribute |\n  |-------------|--------------------------------|\n  | `span.id`   | `span_id`                      |\n  | `trace.id`  | `trace_id`                     |\n  | `message`   | `body.text`                    |\n  | `log.level` | `severity_text`                |\n\n  The processor first looks for the nested form of the ECS field and if such does not exist, it looks for a top-level field with the dotted field name.\n* Other specific ECS fields that describe resources and have corresponding counterparts in the OpenTelemetry Semantic Conventions are moved to the `resource.attribtues` map. Fields that are considered resource attributes are such that conform to the following conditions:\n    * They are ECS fields that have corresponding counterparts (either with\n      the same name or with a different name) in OpenTelemetry Semantic Conventions.\n    * The corresponding OpenTelemetry attribute is defined in\n      [Semantic Conventions](https://github.com/open-telemetry/semantic-conventions/tree/main/model)\n      within a group that is defined as `type: enitity`.\n* All other fields, except for `@timestamp`, are moved to the `attributes` map.\n* All non-array entries of the `attributes` and `resource.attributes` maps are flattened. Flattening means that nested objects are merged into their parent object, and the keys are concatenated with a dot. See examples below.\n\n## Examples\n\nIf an OpenTelemetry-compliant document is detected, the processor does nothing. For example, the following document will stay unchanged:\n\n```json\n{\n  \"resource\": {\n    \"attributes\": {\n      \"service.name\": \"my-service\"\n    }\n  },\n  \"scope\": {\n    \"name\": \"my-library\",\n    \"version\": \"1.0.0\"\n  },\n  \"attributes\": {\n    \"http.method\": \"GET\"\n  },\n  \"body\": {\n    \"text\": \"Hello, world!\"\n  }\n}\n```\n\nIf a non-OpenTelemetry-compliant document is detected, the processor normalizes it. For example, the following document:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:00:00Z\",\n  \"service\": {\n    \"name\": \"my-service\",\n    \"version\": \"1.0.0\",\n    \"environment\": \"production\",\n    \"language\": {\n      \"name\": \"python\",\n      \"version\": \"3.8\"\n    }\n  },\n  \"log\": {\n    \"level\": \"INFO\"\n  },\n  \"message\": \"Hello, world!\",\n  \"http\": {\n    \"method\": \"GET\",\n    \"url\": {\n      \"path\": \"/api/v1/resource\"\n    },\n    \"headers\": [\n      {\n        \"name\": \"Authorization\",\n        \"value\": \"Bearer token\"\n      },\n      {\n        \"name\": \"User-Agent\",\n        \"value\": \"my-client/1.0\"\n      }\n    ]\n  },\n  \"span\" : {\n    \"id\": \"1234567890abcdef\"\n  },\n  \"span.id\": \"abcdef1234567890\",\n  \"trace.id\": \"abcdef1234567890abcdef1234567890\"\n}\n```\nwill be normalized into the following form:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:00:00Z\",\n  \"resource\": {\n    \"attributes\": {\n      \"service.name\": \"my-service\",\n      \"service.version\": \"1.0.0\",\n      \"service.environment\": \"production\"\n    }\n  },\n  \"attributes\": {\n    \"service.language.name\": \"python\",\n    \"service.language.version\": \"3.8\",\n    \"http.method\": \"GET\",\n    \"http.url.path\": \"/api/v1/resource\",\n    \"http.headers\": [\n      {\n        \"name\": \"Authorization\",\n        \"value\": \"Bearer token\"\n      },\n      {\n        \"name\": \"User-Agent\",\n        \"value\": \"my-client/1.0\"\n      }\n    ]\n  },\n  \"body\": {\n    \"text\": \"Hello, world!\"\n  },\n  \"span_id\": \"1234567890abcdef\",\n  \"trace_id\": \"abcdef1234567890abcdef1234567890\"\n}\n```\n## Structured `message` field\n\nIf the `message` field in the ingested document is structured as a JSON, the\nprocessor will determine whether it is in ECS format or not, based on the\nexistence or absence of the `@timestamp` field. If the `@timestamp` field is\npresent, the `message` field will be considered to be in ECS format, and its\ncontents will be merged into the root of the document and then normalized as\ndescribed above. The `@timestamp` from the `message` field will override the\nroot `@timestamp` field in the resulting document.\nIf the `@timestamp` field is absent, the `message` field will be moved to\nthe `body.structured` field as is, without any further normalization.\n\nFor example, if the `message` field is an ECS-JSON, as follows:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:00:00Z\",\n  \"message\": \"{\\\"@timestamp\\\":\\\"2023-10-01T12:01:00Z\\\",\\\"log.level\\\":\\\"INFO\\\",\\\"service.name\\\":\\\"my-service\\\",\\\"message\\\":\\\"The actual log message\\\",\\\"http\\\":{\\\"method\\\":\\\"GET\\\",\\\"url\\\":{\\\"path\\\":\\\"/api/v1/resource\\\"}}}\"\n\n}\n```\nit will be normalized into the following form:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:01:00Z\",\n  \"severity_text\": \"INFO\",\n  \"body\": {\n    \"text\": \"The actual log message\"\n  },\n  \"resource\": {\n    \"attributes\": {\n      \"service.name\": \"my-service\"\n    }\n  },\n  \"attributes\": {\n    \"http.method\": \"GET\",\n    \"http.url.path\": \"/api/v1/resource\"\n  }\n}\n```\n\nHowever, if the `message` field is not recognized as ECS format, as follows:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:00:00Z\",\n  \"log\": {\n    \"level\": \"INFO\"\n  },\n  \"service\": {\n    \"name\": \"my-service\"\n  },\n  \"tags\": [\"user-action\", \"api-call\"],\n  \"message\": \"{\\\"root_cause\\\":\\\"Network error\\\",\\\"http\\\":{\\\"method\\\":\\\"GET\\\",\\\"url\\\":{\\\"path\\\":\\\"/api/v1/resource\\\"}}}\"\n}\n```\nit will be normalized into the following form:\n\n```json\n{\n  \"@timestamp\": \"2023-10-01T12:00:00Z\",\n  \"severity_text\": \"INFO\",\n  \"resource\": {\n    \"attributes\": {\n      \"service.name\": \"my-service\"\n    }\n  },\n  \"attributes\": {\n    \"tags\": [\"user-action\", \"api-call\"]\n  },\n  \"body\": {\n    \"structured\": {\n      \"root_cause\": \"Network error\",\n      \"http\": {\n        \"method\": \"GET\",\n        \"url\": {\n          \"path\": \"/api/v1/resource\"\n        }\n      }\n    }\n  }\n}\n```",
              "filename": "elasticsearch-main/docs/reference/enrich-processor/normalize-for-stream.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html"
              ],
              "navigation_title": "Similarity",
              "applies_to": {
                "stack": "all",
                "serverless": "all"
              },
              "content": "# Similarity settings [index-modules-similarity]\n\nA similarity (scoring / ranking model) defines how matching documents are scored. Similarity is per field, meaning that via the mapping one can define a different similarity per field.\n\nSimilarity is only applicable for text type and keyword type fields.\n\nConfiguring a custom similarity is considered an expert feature and the builtin similarities are most likely sufficient as is described in [`similarity`](/reference/elasticsearch/mapping-reference/similarity.md).\n\n\n## Configuring a similarity [configuration]\n\nMost existing or custom Similarities have configuration options which can be configured via the index settings as shown below. The index options can be provided when creating an index or updating index settings.\n\n```console\nPUT /index\n{\n  \"settings\": {\n    \"index\": {\n      \"similarity\": {\n        \"my_similarity\": {\n          \"type\": \"DFR\",\n          \"basic_model\": \"g\",\n          \"after_effect\": \"l\",\n          \"normalization\": \"h2\",\n          \"normalization.h2.c\": \"3.0\"\n        }\n      }\n    }\n  }\n}\n```\n\nHere we configure the DFR similarity so it can be referenced as `my_similarity` in mappings as is illustrate in the below example:\n\n```console\nPUT /index/_mapping\n{\n  \"properties\" : {\n    \"title\" : { \"type\" : \"text\", \"similarity\" : \"my_similarity\" }\n  }\n}\n```\n\n\n## Available similarities [_available_similarities]\n\n\n### BM25 similarity (**default**) [bm25]\n\nTF/IDF based similarity that has built-in tf normalization and is supposed to work better for short fields (like names). See [Okapi_BM25](https://en.wikipedia.org/wiki/Okapi_BM25) for more details. This similarity has the following options:\n\n`k1`\n:   Controls non-linear term frequency normalization (saturation). The default value is `1.2`.\n\n`b`\n:   Controls to what degree document length normalizes tf values. The default value is `0.75`.\n\n`discount_overlaps`\n:   Determines whether overlap tokens (Tokens with 0 position increment) are ignored when computing norm. By default this is true, meaning overlap tokens do not count when computing norms.\n\nType name: `BM25`\n\n\n### DFR similarity [dfr]\n\nSimilarity that implements the [divergence from randomness](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/DFRSimilarity.md) framework. This similarity has the following options:\n\n`basic_model`\n:   Possible values: [`g`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/BasicModelG.md), [`if`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/BasicModelIF.md), [`in`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/BasicModelIn.md) and [`ine`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/BasicModelIne.md).\n\n`after_effect`\n:   Possible values: [`b`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/AfterEffectB.md) and [`l`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/AfterEffectL.md).\n\n`normalization`\n:   Possible values: [`no`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/Normalization.NoNormalization.md), [`h1`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/NormalizationH1.md), [`h2`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/NormalizationH2.md), [`h3`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/NormalizationH3.md) and [`z`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/NormalizationZ.md).\n\nAll options but the first option need a normalization value.\n\nType name: `DFR`\n\n\n### DFI similarity [dfi]\n\nSimilarity that implements the [divergence from independence](https://trec.nist.gov/pubs/trec21/papers/irra.web.nb.pdf) model. This similarity has the following options:\n\n`independence_measure`\n:   Possible values [`standardized`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/IndependenceStandardized.md), [`saturated`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/IndependenceSaturated.md), [`chisquared`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/IndependenceChiSquared.md).\n\nWhen using this similarity, it is highly recommended **not** to remove stop words to get good relevance. Also beware that terms whose frequency is less than the expected frequency will get a score equal to 0.\n\nType name: `DFI`\n\n\n### IB similarity. [ib]\n\n[Information based model](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/IBSimilarity.md) . The algorithm is based on the concept that the information content in any symbolic *distribution* sequence is primarily determined by the repetitive usage of its basic elements. For written texts this challenge would correspond to comparing the writing styles of different authors. This similarity has the following options:\n\n`distribution`\n:   Possible values: [`ll`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/DistributionLL.md) and [`spl`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/DistributionSPL.md).\n\n`lambda`\n:   Possible values: [`df`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/LambdaDF.md) and [`ttf`](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/LambdaTTF.md).\n\n`normalization`\n:   Same as in `DFR` similarity.\n\nType name: `IB`\n\n\n### LM Dirichlet similarity. [lm_dirichlet]\n\n[LM Dirichlet similarity](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/LMDirichletSimilarity.md) . This similarity has the following options:\n\n`mu`\n:   Default to `2000`.\n\nThe scoring formula in the paper assigns negative scores to terms that have fewer occurrences than predicted by the language model, which is illegal to Lucene, so such terms get a score of 0.\n\nType name: `LMDirichlet`\n\n\n### LM Jelinek Mercer similarity. [lm_jelinek_mercer]\n\n[LM Jelinek Mercer similarity](https://lucene.apache.org/core/10_0_0/core/org/apache/lucene/search/similarities/LMJelinekMercerSimilarity.md) . The algorithm attempts to capture important patterns in the text, while leaving out noise. This similarity has the following options:\n\n`lambda`\n:   The optimal value depends on both the collection and the query. The optimal value is around `0.1` for title queries and `0.7` for long queries. Default to `0.1`. When value approaches `0`, documents that match more query terms will be ranked higher than those that match fewer terms.\n\nType name: `LMJelinekMercer`\n\n\n### Scripted similarity [scripted_similarity]\n\nA similarity that allows you to use a script in order to specify how scores should be computed. For instance, the below example shows how to reimplement TF-IDF:\n\n```console\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"similarity\": {\n      \"scripted_tfidf\": {\n        \"type\": \"scripted\",\n        \"script\": {\n          \"source\": \"double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"text\",\n        \"similarity\": \"scripted_tfidf\"\n      }\n    }\n  }\n}\n\nPUT /index/_doc/1\n{\n  \"field\": \"foo bar foo\"\n}\n\nPUT /index/_doc/2\n{\n  \"field\": \"bar baz\"\n}\n\nPOST /index/_refresh\n\nGET /index/_search?explain=true\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"foo^1.7\",\n      \"default_field\": \"field\"\n    }\n  }\n}\n```\n\nWhich yields:\n\n```console-result\n{\n  \"took\": 12,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 1.9508477,\n    \"hits\": [\n      {\n        \"_shard\": \"[index][0]\",\n        \"_node\": \"OzrdjxNtQGaqs4DmioFw9A\",\n        \"_index\": \"index\",\n        \"_id\": \"1\",\n        \"_score\": 1.9508477,\n        \"_source\": {\n          \"field\": \"foo bar foo\"\n        },\n        \"_explanation\": {\n          \"value\": 1.9508477,\n          \"description\": \"weight(field:foo in 0) [PerFieldSimilarity], result of:\",\n          \"details\": [\n            {\n              \"value\": 1.9508477,\n              \"description\": \"score from ScriptedSimilarity(weightScript=[null], script=[Script{type=inline, lang='painless', idOrCode='double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;', options={}, params={}}]) computed from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"weight\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1.7,\n                  \"description\": \"query.boost\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2,\n                  \"description\": \"field.docCount\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 4,\n                  \"description\": \"field.sumDocFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 5,\n                  \"description\": \"field.sumTotalTermFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 1,\n                  \"description\": \"term.docFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2,\n                  \"description\": \"term.totalTermFreq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.0,\n                  \"description\": \"doc.freq\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3,\n                  \"description\": \"doc.length\",\n                  \"details\": []\n                }\n              ]\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n::::{warning}\nWhile scripted similarities provide a lot of flexibility, there is a set of rules that they need to satisfy. Failing to do so could make Elasticsearch silently return wrong top hits or fail with internal errors at search time:\n::::\n\n\n* Returned scores must be positive.\n* All other variables remaining equal, scores must not decrease when `doc.freq` increases.\n* All other variables remaining equal, scores must not increase when `doc.length` increases.\n\nYou might have noticed that a significant part of the above script depends on statistics that are the same for every document. It is possible to make the above slightly more efficient by providing an `weight_script` which will compute the document-independent part of the score and will be available under the `weight` variable. When no `weight_script` is provided, `weight` is equal to `1`. The `weight_script` has access to the same variables as the `script` except `doc` since it is supposed to compute a document-independent contribution to the score.\n\nThe below configuration will give the same tf-idf scores but is slightly more efficient:\n\n```console\nPUT /index\n{\n  \"settings\": {\n    \"number_of_shards\": 1,\n    \"similarity\": {\n      \"scripted_tfidf\": {\n        \"type\": \"scripted\",\n        \"weight_script\": {\n          \"source\": \"double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; return query.boost * idf;\"\n        },\n        \"script\": {\n          \"source\": \"double tf = Math.sqrt(doc.freq); double norm = 1/Math.sqrt(doc.length); return weight * tf * norm;\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"field\": {\n        \"type\": \"text\",\n        \"similarity\": \"scripted_tfidf\"\n      }\n    }\n  }\n}\n```\n\nType name: `scripted`\n\n\n### Default Similarity [default-base]\n\nBy default, Elasticsearch will use whatever similarity is configured as `default`.\n\nYou can change the default similarity for all fields in an index when it is [created](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-create):\n\n```console\nPUT /index\n{\n  \"settings\": {\n    \"index\": {\n      \"similarity\": {\n        \"default\": {\n          \"type\": \"boolean\"\n        }\n      }\n    }\n  }\n}\n```\n\nIf you want to change the default similarity after creating the index you must [close](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-open) your index, send the following request and [open](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-open) it again afterwards:\n\n```console\nPOST /index/_close\n\nPUT /index/_settings\n{\n  \"index\": {\n    \"similarity\": {\n      \"default\": {\n        \"type\": \"boolean\"\n      }\n    }\n  }\n}\n\nPOST /index/_open\n```",
              "filename": "elasticsearch-main/docs/reference/elasticsearch/index-settings/similarity.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-field-meta.html"
              ],
              "content": "# meta [mapping-field-meta]\n\nMetadata attached to the field. This metadata is opaque to Elasticsearch, it is only useful for multiple applications that work on the same indices to share meta information about fields such as units\n\n```console\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"latency\": {\n        \"type\": \"long\",\n        \"meta\": {\n          \"unit\": \"ms\"\n        }\n      }\n    }\n  }\n}\n```\n\n::::{note}\nField metadata enforces at most 5 entries, that keys have a length that is less than or equal to 20, and that values are strings whose length is less than or equal to 50.\n::::\n\n\n::::{note}\nField metadata is updatable by submitting a mapping update. The metadata of the update will override the metadata of the existing field.\n::::\n\n\n::::{note}\nField metadata is not supported on object or nested fields.\n::::\n\n\nElastic products use the following standard metadata entries for fields. You can follow these same metadata conventions to get a better out-of-the-box experience with your data.\n\nunit\n:   The unit associated with a numeric field: `\"percent\"`, `\"byte\"` or a [time unit](/reference/elasticsearch/rest-apis/api-conventions.md#time-units). By default, a field does not have a unit. Only valid for numeric fields. The convention for percents is to use value `1` to mean `100%`.\n\nmetric_type\n:   The metric type of a numeric field: `\"gauge\"` or `\"counter\"`. A gauge is a single-value measurement that can go up or down over time, such as a temperature. A counter is a single-value cumulative counter that only goes up, such as the number of requests processed by a web server, or resets to 0 (zero). By default, no metric type is associated with a field. Only valid for numeric fields.",
              "filename": "elasticsearch-main/docs/reference/elasticsearch/mapping-reference/mapping-field-meta.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-normalization.html"
              ],
              "content": "# ICU normalization token filter [analysis-icu-normalization]\n\nNormalizes characters as explained [here](https://unicode-org.github.io/icu/userguide/transforms/normalization/). It registers itself as the `icu_normalizer` token filter, which is available to all indices without any further configuration. The type of normalization can be specified with the `name` parameter, which accepts `nfc`, `nfkc`, and `nfkc_cf` (default).\n\nWhich letters are normalized can be controlled by specifying the `unicode_set_filter` parameter, which accepts a [UnicodeSet](https://icu-project.org/apiref/icu4j/com/ibm/icu/text/UnicodeSet.md).\n\nYou should probably prefer the [Normalization character filter](/reference/elasticsearch-plugins/analysis-icu-normalization-charfilter.md).\n\nHere are two examples, the default usage and a customised token filter:\n\n```console\nPUT icu_sample\n{\n  \"settings\": {\n    \"index\": {\n      \"analysis\": {\n        \"analyzer\": {\n          \"nfkc_cf_normalized\": { <1>\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"icu_normalizer\"\n            ]\n          },\n          \"nfc_normalized\": { <2>\n            \"tokenizer\": \"icu_tokenizer\",\n            \"filter\": [\n              \"nfc_normalizer\"\n            ]\n          }\n        },\n        \"filter\": {\n          \"nfc_normalizer\": {\n            \"type\": \"icu_normalizer\",\n            \"name\": \"nfc\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n1. Uses the default `nfkc_cf` normalization.\n2. Uses the customized `nfc_normalizer` token filter, which is set to use `nfc` normalization.",
              "filename": "elasticsearch-main/docs/reference/elasticsearch-plugins/analysis-icu-normalization.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/norms.html"
              ],
              "content": "# norms [norms]\n\nNorms store various normalization factors that are later used at query time in order to compute the score of a document relatively to a query.\n\nAlthough useful for scoring, norms also require quite a lot of disk (typically in the order of one byte per document per field in your index, even for documents that don\u2019t have this specific field). As a consequence, if you don\u2019t need scoring on a specific field, you should disable norms on that field. In particular, this is the case for fields that are used solely for filtering or aggregations.\n\n::::{tip}\nNorms can be disabled on existing fields using the [update mapping API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-put-mapping).\n::::\n\n\nNorms can be disabled (but not reenabled after the fact), using the [update mapping API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-indices-put-mapping) like so:\n\n```console\nPUT my-index-000001/_mapping\n{\n  \"properties\": {\n    \"title\": {\n      \"type\": \"text\",\n      \"norms\": false\n    }\n  }\n}\n```\n\n::::{note}\nNorms will not be removed instantly, but will be removed as old segments are merged into new segments as you continue indexing new documents. Any score computation on a field that has had norms removed might return inconsistent results since some documents won\u2019t have norms anymore while other documents might still have norms.\n::::",
              "filename": "elasticsearch-main/docs/reference/elasticsearch/mapping-reference/norms.md"
            }
          ],
          "tool_call_id": "call_Xr0I1V0wtl0F4yKAoy55vxFj",
          "metadata": null,
          "timestamp": "2025-10-03T06:00:35.294171+00:00",
          "part_kind": "tool-return"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "content": "When a non-OpenTelemetry-compliant document is detected, the **Normalize-for-Stream** processor takes specific actions to normalize the document's attributes. Here's how this normalization process occurs:\n\n1. **Detection of OpenTelemetry Compliance**:\n   - The processor first checks for certain fields to determine if the document is OpenTelemetry-compliant, including the presence and type of `resource`, `scope`, `attributes`, and `body` fields.\n\n2. **Normalization Process**:\n   - If the document is found not to be compliant, the normalization is performed as follows:\n     - **Renaming Specific Fields**: ECS fields are renamed according to OpenTelemetry Semantic Conventions. For example:\n       - `span.id` is changed to `span_id`\n       - `trace.id` is renamed to `trace_id`\n       - `message` is converted to `body.text`\n       - `log.level` is transformed into `severity_text`\n     - The processor looks for nested forms of ECS fields first. If they do not exist, it will check for top-level fields with dotted names.\n     \n     - **Moving Resource Attributes**: ECS fields that describe resources and have corresponding names in OpenTelemetry are moved to the `resource.attributes` map. The fields must comply with the attributes defined in OpenTelemetry's Semantic Conventions.\n     \n     - **Reorganizing Other Fields**: All other fields, apart from `@timestamp`, are transferred to the `attributes` map. Non-array entries within the `attributes` and `resource.attributes` maps are also flattened, which means nested objects are merged into their parent object with keys concatenated using a dot, ensuring a more structured format.\n\n3. **Concrete Example**: \n   - Given a non-compliant document like:\n     ```json\n     {\n       \"@timestamp\": \"2023-10-01T12:00:00Z\",\n       \"service\": {\n         \"name\": \"my-service\",\n         \"version\": \"1.0.0\",\n         \"environment\": \"production\",\n         \"language\": {\n           \"name\": \"python\",\n           \"version\": \"3.8\"\n         }\n       },\n       \"log\": {\n         \"level\": \"INFO\"\n       },\n       \"message\": \"Hello, world!\",\n       \"http\": {\n         \"method\": \"GET\",\n         \"url\": {\n           \"path\": \"/api/v1/resource\"\n         },\n         \"headers\": [\n           {\"name\": \"Authorization\", \"value\": \"Bearer token\"},\n           {\"name\": \"User-Agent\", \"value\": \"my-client/1.0\"}\n         ]\n       },\n       \"span\": {\n         \"id\": \"1234567890abcdef\"\n       },\n       \"span.id\": \"abcdef1234567890\",\n       \"trace.id\": \"abcdef1234567890abcdef1234567890\"\n     }\n     ```\n   - It would be normalized to:\n     ```json\n     {\n       \"@timestamp\": \"2023-10-01T12:00:00Z\",\n       \"resource\": {\n         \"attributes\": {\n           \"service.name\": \"my-service\",\n           \"service.version\": \"1.0.0\",\n           \"service.environment\": \"production\"\n         }\n       },\n       \"attributes\": {\n         \"service.language.name\": \"python\",\n         \"service.language.version\": \"3.8\",\n         \"http.method\": \"GET\",\n         \"http.url.path\": \"/api/v1/resource\",\n         \"http.headers\": [\n           {\"name\": \"Authorization\", \"value\": \"Bearer token\"},\n           {\"name\": \"User-Agent\", \"value\": \"my-client/1.0\"}\n         ]\n       },\n       \"body\": {\n         \"text\": \"Hello, world!\"\n       },\n       \"span_id\": \"1234567890abcdef\",\n       \"trace_id\": \"abcdef1234567890abcdef1234567890\"\n     }\n     ```\n\nThis normalization ensures that the document can be queried seamlessly by clients expecting either ECS or OpenTelemetry Semantic Conventions formats.\n\nFor more detailed information, you can refer to the documentation in the [Normalize-for-Stream processor](https://github.com/elastic/elasticsearch/blob/main/docs/reference/enrich-processor/normalize-for-stream.md).",
          "id": null,
          "part_kind": "text"
        }
      ],
      "usage": {
        "input_tokens": 7479,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 862,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T06:00:36+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "stop"
      },
      "provider_response_id": "chatcmpl-CMT8GmrbLrKbyVheRdZFMrwzNfwRk",
      "finish_reason": "stop"
    }
  ],
  "source": "ai-generated"
}