{
  "agent_name": "es_agent_v2",
  "system_prompt": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "tools": [
    "search"
  ],
  "messages": [
    {
      "parts": [
        {
          "content": "What is the significance of the Elastic Search PHP client and how does it relate to structuring queries?",
          "timestamp": "2025-10-03T04:05:11.360080+00:00",
          "part_kind": "user-prompt"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "args": "{\"query\":\"Elastic Search PHP client significance structuring queries\"}",
          "tool_call_id": "call_rTaHD0Cs5sKN9qOVqV55O7Qn",
          "part_kind": "tool-call"
        }
      ],
      "usage": {
        "input_tokens": 221,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 20,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T04:05:11+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "tool_calls"
      },
      "provider_response_id": "chatcmpl-CMRKZQhvPI8a3hdJBC2ASvybjJGWA",
      "finish_reason": "tool_call"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "content": [
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-functions-search.html"
              ],
              "content": "# Full-text search functions [sql-functions-search]\n\nSearch functions should be used when performing full-text search, namely when the `MATCH` or `QUERY` predicates are being used. Outside a, so-called, search context, these functions will return default values such as `0` or `NULL`.\n\nElasticsearch SQL optimizes all queries executed against {{es}} depending on the scoring needs. Using [`track_scores`](/reference/elasticsearch/rest-apis/sort-search-results.md#_track_scores) on the search request or [`_doc` sorting](/reference/elasticsearch/rest-apis/sort-search-results.md) that disables scores calculation, Elasticsearch SQL instructs {{es}} not to compute scores when these are not needed. For example, every time a `SCORE()` function is encountered in the SQL query, the scores are computed.\n\n## `MATCH` [sql-functions-search-match]\n\n```sql\nMATCH(\n    field_exp,   <1>\n    constant_exp <2>\n    [, options]) <3>\n```\n\n**Input**:\n\n1. field(s) to match\n2. matching text\n3. additional parameters; optional\n\n\n**Description**: A full-text search option, in the form of a predicate, available in Elasticsearch SQL that gives the user control over powerful [match](/reference/query-languages/query-dsl/query-dsl-match-query.md) and [multi_match](/reference/query-languages/query-dsl/query-dsl-multi-match-query.md) {{es}} queries.\n\nThe first parameter is the field or fields to match against. In case it receives one value only, Elasticsearch SQL will use a `match` query to perform the search:\n\n```sql\nSELECT author, name FROM library WHERE MATCH(author, 'frank');\n\n    author     |       name\n---------------+-------------------\nFrank Herbert  |Dune\nFrank Herbert  |Dune Messiah\nFrank Herbert  |Children of Dune\nFrank Herbert  |God Emperor of Dune\n```\n\nHowever, it can also receive a list of fields and their corresponding optional `boost` value. In this case, Elasticsearch SQL will use a `multi_match` query to match the documents:\n\n```sql\nSELECT author, name, SCORE() FROM library WHERE MATCH('author^2,name^5', 'frank dune');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |Dune               |11.443176\nFrank Herbert  |Dune Messiah       |9.446629\nFrank Herbert  |Children of Dune   |8.043278\nFrank Herbert  |God Emperor of Dune|7.0029488\n```\n\n::::{note}\nThe `multi_match` query in {{es}} has the option of [per-field boosting](/reference/query-languages/query-dsl/query-dsl-multi-match-query.md) that gives preferential weight (in terms of scoring) to fields being searched in, using the `^` character. In the example above, the `name` field has a greater weight in the final score than the `author` field when searching for `frank dune` text in both of them.\n::::\n\n\nBoth options above can be used in combination with the optional third parameter of the `MATCH()` predicate, where one can specify additional configuration parameters (separated by semicolon `;`) for either `match` or `multi_match` queries. For example:\n\n```sql\nSELECT author, name, SCORE() FROM library WHERE MATCH(name, 'to the star', 'operator=OR;fuzziness=AUTO:1,5;minimum_should_match=1')\nORDER BY SCORE() DESC LIMIT 2;\n\n     author      |                name                |    SCORE()\n-----------------+------------------------------------+---------------\nDouglas Adams    |The Hitchhiker's Guide to the Galaxy|3.1756816\nPeter F. Hamilton|Pandora's Star                      |3.0997515\n```\n\n::::{note}\nThe allowed optional parameters for a single-field `MATCH()` variant (for the `match` {{es}} query) are: `analyzer`, `auto_generate_synonyms_phrase_query`, `lenient`, `fuzziness`, `fuzzy_transpositions`, `fuzzy_rewrite`, `minimum_should_match`, `operator`, `max_expansions`, `prefix_length`.\n::::\n\n\n::::{note}\nThe allowed optional parameters for a multi-field `MATCH()` variant (for the `multi_match` {{es}} query) are: `analyzer`, `auto_generate_synonyms_phrase_query`, `lenient`, `fuzziness`, `fuzzy_transpositions`, `fuzzy_rewrite`, `minimum_should_match`, `operator`, `max_expansions`, `prefix_length`, `slop`, `tie_breaker`, `type`.\n::::\n\n\n\n## `QUERY` [sql-functions-search-query]\n\n```sql\nQUERY(\n    constant_exp <1>\n    [, options]) <2>\n```\n\n**Input**:\n\n1. query text\n2. additional parameters; optional\n\n\n**Description**: Just like `MATCH`, `QUERY` is a full-text search predicate that gives the user control over the [query_string](/reference/query-languages/query-dsl/query-dsl-query-string-query.md) query in {{es}}.\n\nThe first parameter is basically the input that will be passed as is to the `query_string` query, which means that anything that `query_string` accepts in its `query` field can be used here as well:\n\n```sql\nSELECT author, name, SCORE() FROM library WHERE QUERY('name:dune');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |Dune               |2.2886353\nFrank Herbert  |Dune Messiah       |1.8893257\nFrank Herbert  |Children of Dune   |1.6086556\nFrank Herbert  |God Emperor of Dune|1.4005898\n```\n\nA more advanced example, showing more of the features that `query_string` supports, of course possible with Elasticsearch SQL:\n\n```sql\nSELECT author, name, page_count, SCORE() FROM library WHERE QUERY('_exists_:\"author\" AND page_count:>200 AND (name:/star.*/ OR name:duna~)');\n\n      author      |       name        |  page_count   |    SCORE()\n------------------+-------------------+---------------+---------------\nFrank Herbert     |Dune               |604            |3.7164764\nFrank Herbert     |Dune Messiah       |331            |3.4169943\nFrank Herbert     |Children of Dune   |408            |3.2064917\nFrank Herbert     |God Emperor of Dune|454            |3.0504425\nPeter F. Hamilton |Pandora's Star     |768            |3.0\nRobert A. Heinlein|Starship Troopers  |335            |3.0\n```\n\nThe query above uses the `_exists_` query to select documents that have values in the `author` field, a range query for `page_count` and regex and fuzziness queries for the `name` field.\n\nIf one needs to customize various configuration options that `query_string` exposes, this can be done using the second *optional* parameter. Multiple settings can be specified separated by a semicolon `;`:\n\n```sql\nSELECT author, name, SCORE() FROM library WHERE QUERY('dune god', 'default_operator=and;default_field=name');\n\n    author     |       name        |    SCORE()\n---------------+-------------------+---------------\nFrank Herbert  |God Emperor of Dune|3.6984892\n```\n\n::::{note}\nThe allowed optional parameters for `QUERY()` are: `allow_leading_wildcard`, `analyze_wildcard`, `analyzer`, `auto_generate_synonyms_phrase_query`, `default_field`, `default_operator`, `enable_position_increments`, `escape`, `fuzziness`, `fuzzy_max_expansions`, `fuzzy_prefix_length`, `fuzzy_rewrite`, `fuzzy_transpositions`, `lenient`, `max_determinized_states`, `minimum_should_match`, `phrase_slop`, `rewrite`, `quote_analyzer`, `quote_field_suffix`, `tie_breaker`, `time_zone`, `type`.\n::::\n\n\n\n## `SCORE` [sql-functions-search-score]\n\n```sql\nSCORE()\n```\n\n**Input**: *none*\n\n**Output**: `double` numeric value\n\n**Description**: Returns the [relevance](https://www.elastic.co/guide/en/elasticsearch/guide/2.x/relevance-intro.html) of a given input to the executed query. The higher score, the more relevant the data.\n\n::::{note}\nWhen doing multiple text queries in the `WHERE` clause then, their scores will be combined using the same rules as {{es}}'s [bool query](/reference/query-languages/query-dsl/query-dsl-bool-query.md).\n::::\n\n\nTypically `SCORE` is used for ordering the results of a query based on their relevance:\n\n```sql\nSELECT SCORE(), * FROM library WHERE MATCH(name, 'dune') ORDER BY SCORE() DESC;\n\n    SCORE()    |    author     |       name        |  page_count   |    release_date\n---------------+---------------+-------------------+---------------+--------------------\n2.2886353      |Frank Herbert  |Dune               |604            |1965-06-01T00:00:00Z\n1.8893257      |Frank Herbert  |Dune Messiah       |331            |1969-10-15T00:00:00Z\n1.6086556      |Frank Herbert  |Children of Dune   |408            |1976-04-21T00:00:00Z\n1.4005898      |Frank Herbert  |God Emperor of Dune|454            |1981-05-28T00:00:00Z\n```\n\nHowever, it is perfectly fine to return the score without sorting by it:\n\n```sql\nSELECT SCORE() AS score, name, release_date FROM library WHERE QUERY('dune') ORDER BY YEAR(release_date) DESC;\n\n     score     |       name        |    release_date\n---------------+-------------------+--------------------\n1.4005898      |God Emperor of Dune|1981-05-28T00:00:00Z\n1.6086556      |Children of Dune   |1976-04-21T00:00:00Z\n1.8893257      |Dune Messiah       |1969-10-15T00:00:00Z\n2.2886353      |Dune               |1965-06-01T00:00:00Z\n```",
              "filename": "elasticsearch-main/docs/reference/query-languages/sql/sql-functions-search.md"
            },
            {
              "navigation_title": "REST API",
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-rest.html"
              ],
              "applies_to": {
                "stack": "ga",
                "serverless": "ga"
              },
              "products": [
                {
                  "id": "elasticsearch"
                }
              ],
              "content": "# Use the {{esql}} REST API [esql-rest]\n\n::::{tip}\nThe [Search and filter with {{esql}}](/reference/query-languages/esql/esql-search-tutorial.md) tutorial provides a hands-on introduction to the {{esql}} `_query` API.\n::::\n\n## Overview [esql-rest-overview]\n\nThe [`_query` API](https://www.elastic.co/docs/api/doc/elasticsearch/group/endpoint-esql) accepts an {{esql}} query string in the `query` parameter, runs it, and returns the results. For example:\n\n```console\nPOST /_query?format=txt\n{\n  \"query\": \"FROM library | KEEP author, name, page_count, release_date | SORT page_count DESC | LIMIT 5\"\n}\n```\n\nWhich returns:\n\n```text\n     author      |        name        |  page_count   | release_date\n-----------------+--------------------+---------------+------------------------\nPeter F. Hamilton|Pandora's Star      |768            |2004-03-02T00:00:00.000Z\nVernor Vinge     |A Fire Upon the Deep|613            |1992-06-01T00:00:00.000Z\nFrank Herbert    |Dune                |604            |1965-06-01T00:00:00.000Z\nAlastair Reynolds|Revelation Space    |585            |2000-03-15T00:00:00.000Z\nJames S.A. Corey |Leviathan Wakes     |561            |2011-06-02T00:00:00.000Z\n```\n\n\n### Run the {{esql}} query API in Console [esql-kibana-console]\n\nWe recommend using [Console](docs-content://explore-analyze/query-filter/tools/console.md) to run the {{esql}} query API, because of its rich autocomplete features.\n\nWhen creating the query, using triple quotes (`\"\"\"`) allows you to use special characters like quotes (`\"`) without having to escape them. They also make it easier to write multi-line requests.\n\n```console\nPOST /_query?format=txt\n{\n  \"query\": \"\"\"\n    FROM library\n    | KEEP author, name, page_count, release_date\n    | SORT page_count DESC\n    | LIMIT 5\n  \"\"\"\n}\n```\n\n### Response formats [esql-rest-format]\n\n{{esql}} can return the data in the following human readable and binary formats. You can set the format by specifying the `format` parameter in the URL or by setting the `Accept` or `Content-Type` HTTP header.\n\nFor example:\n\n```console\nPOST /_query?format=yaml\n```\n\n::::{note}\nThe URL parameter takes precedence over the HTTP headers. If neither is specified then the response is returned in the same format as the request.\n::::\n\n#### Structured formats\n\nComplete responses with metadata. Useful for automatic parsing.\n\n| `format` | HTTP header | Description |\n| --- | --- | --- |\n| `json` | `application/json` | [JSON](https://www.json.org/) (JavaScript Object Notation) human-readable format |\n| `yaml` | `application/yaml` | [YAML](https://en.wikipedia.org/wiki/YAML) (YAML Ain\u2019t Markup Language) human-readable format |\n\n#### Tabular formats\n\nQuery results only, without metadata. Useful for quick and manual data previews.\n\n| `format` | HTTP header | Description |\n| --- | --- | --- |\n| `csv` | `text/csv` | [Comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) |\n| `tsv` | `text/tab-separated-values` | [Tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values) |\n| `txt` | `text/plain` | CLI-like representation |\n\n::::{tip}\nThe `csv` format accepts a formatting URL query attribute, `delimiter`, which indicates which character should be used to separate the CSV values. It defaults to comma (`,`) and cannot take any of the following values: double quote (`\"`), carriage-return (`\\r`) and new-line (`\\n`). The tab (`\\t`) can also not be used. Use the `tsv` format instead.\n::::\n\n#### Binary formats\n\nCompact binary encoding. To be used by applications.\n\n| `format` | HTTP header | Description |\n| --- | --- | --- |\n| `cbor` | `application/cbor` | [Concise Binary Object Representation](https://cbor.io/) |\n| `smile` | `application/smile` | [Smile](https://en.wikipedia.org/wiki/Smile_(data_interchange_format)) binary data format similarto CBOR |\n| `arrow` | `application/vnd.apache.arrow.stream` | **Experimental.** [Apache Arrow](https://arrow.apache.org/) dataframes, [IPC streaming format](https://arrow.apache.org/docs/format/Columnar.html#ipc-streaming-format) |\n\n\n### Filtering using {{es}} Query DSL [esql-rest-filtering]\n\nSpecify a Query DSL query in the `filter` parameter to filter the set of documents that an {{esql}} query runs on.\n\n```console\nPOST /_query?format=txt\n{\n  \"query\": \"\"\"\n    FROM library\n    | KEEP author, name, page_count, release_date\n    | SORT page_count DESC\n    | LIMIT 5\n  \"\"\",\n  \"filter\": {\n    \"range\": {\n      \"page_count\": {\n        \"gte\": 100,\n        \"lte\": 200\n      }\n    }\n  }\n}\n```\n\nWhich returns:\n\n```text\n    author     |                name                |  page_count   | release_date\n---------------+------------------------------------+---------------+------------------------\nDouglas Adams  |The Hitchhiker's Guide to the Galaxy|180            |1979-10-12T00:00:00.000Z\n```\n\n\n### Columnar results [esql-rest-columnar]\n\nBy default, {{esql}} returns results as rows. For example, `FROM` returns each individual document as one row. For the `json`, `yaml`, `cbor` and `smile` [formats](#esql-rest-format), {{esql}} can return the results in a columnar fashion where one row represents all the values of a certain column in the results.\n\n```console\nPOST /_query?format=json\n{\n  \"query\": \"\"\"\n    FROM library\n    | KEEP author, name, page_count, release_date\n    | SORT page_count DESC\n    | LIMIT 5\n  \"\"\",\n  \"columnar\": true\n}\n```\n\nWhich returns:\n\n```console-result\n{\n  \"took\": 28,\n  \"is_partial\": false,\n  \"columns\": [\n    {\"name\": \"author\", \"type\": \"text\"},\n    {\"name\": \"name\", \"type\": \"text\"},\n    {\"name\": \"page_count\", \"type\": \"integer\"},\n    {\"name\": \"release_date\", \"type\": \"date\"}\n  ],\n  \"values\": [\n    [\"Peter F. Hamilton\", \"Vernor Vinge\", \"Frank Herbert\", \"Alastair Reynolds\", \"James S.A. Corey\"],\n    [\"Pandora's Star\", \"A Fire Upon the Deep\", \"Dune\", \"Revelation Space\", \"Leviathan Wakes\"],\n    [768, 613, 604, 585, 561],\n    [\"2004-03-02T00:00:00.000Z\", \"1992-06-01T00:00:00.000Z\", \"1965-06-01T00:00:00.000Z\", \"2000-03-15T00:00:00.000Z\", \"2011-06-02T00:00:00.000Z\"]\n  ]\n}\n```\n\n\n### Returning localized results [esql-locale-param]\n\nUse the `locale` parameter in the request body to return results (especially dates) formatted per the conventions of the locale. If `locale` is not specified, defaults to `en-US` (English). Refer to [JDK Supported Locales](https://www.oracle.com/java/technologies/javase/jdk17-suported-locales.html).\n\nSyntax: the `locale` parameter accepts language tags in the (case-insensitive) format `xy` and `xy-XY`.\n\nFor example, to return a month name in French:\n\n```console\nPOST /_query\n{\n  \"locale\": \"fr-FR\",\n  \"query\": \"\"\"\n          ROW birth_date_string = \"2023-01-15T00:00:00.000Z\"\n          | EVAL birth_date = date_parse(birth_date_string)\n          | EVAL month_of_birth = DATE_FORMAT(\"MMMM\",birth_date)\n          | LIMIT 5\n   \"\"\"\n}\n```\n\n\n### Passing parameters to a query [esql-rest-params]\n\nValues, for example for a condition, can be passed to a query \"inline\", by integrating the value in the query string itself:\n\n```console\nPOST /_query\n{\n  \"query\": \"\"\"\n    FROM library\n    | EVAL year = DATE_EXTRACT(\"year\", release_date)\n    | WHERE page_count > 300 AND author == \"Frank Herbert\"\n    | STATS count = COUNT(*) by year\n    | WHERE count > 0\n    | LIMIT 5\n  \"\"\"\n}\n```\n\nTo avoid any attempts of hacking or code injection, extract the values in a separate list of parameters. Use question mark placeholders (`?`) in the query string for each of the parameters:\n\n```console\nPOST /_query\n{\n  \"query\": \"\"\"\n    FROM library\n    | EVAL year = DATE_EXTRACT(\"year\", release_date)\n    | WHERE page_count > ? AND author == ?\n    | STATS count = COUNT(*) by year\n    | WHERE count > ?\n    | LIMIT 5\n  \"\"\",\n  \"params\": [300, \"Frank Herbert\", 0]\n}\n```\n\nThe parameters can be named parameters or positional parameters.\n\nNamed parameters use question mark placeholders (`?`) followed by a string.\n\n```console\nPOST /_query\n{\n  \"query\": \"\"\"\n    FROM library\n    | EVAL year = DATE_EXTRACT(\"year\", release_date)\n    | WHERE page_count > ?page_count AND author == ?author\n    | STATS count = COUNT(*) by year\n    | WHERE count > ?count\n    | LIMIT 5\n  \"\"\",\n  \"params\": [{\"page_count\" : 300}, {\"author\" : \"Frank Herbert\"}, {\"count\" : 0}]\n}\n```\n\nPositional parameters use question mark placeholders (`?`) followed by an integer.\n\n```console\nPOST /_query\n{\n  \"query\": \"\"\"\n    FROM library\n    | EVAL year = DATE_EXTRACT(\"year\", release_date)\n    | WHERE page_count > ?1 AND author == ?2\n    | STATS count = COUNT(*) by year\n    | WHERE count > ?3\n    | LIMIT 5\n  \"\"\",\n  \"params\": [300, \"Frank Herbert\", 0]\n}\n```\n\n\n### Running an async {{esql}} query [esql-rest-async-query]\n\nThe [{{esql}} async query API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-esql-async-query) lets you asynchronously execute a query request, monitor its progress, and retrieve results when they become available.\n\nExecuting an {{esql}} query is commonly quite fast, however queries across large data sets or frozen data can take some time. To avoid long waits, run an async {{esql}} query.\n\nQueries initiated by the async query API may return results or not. The `wait_for_completion_timeout` property determines how long to wait for the results. If the results are not available by this time, a [query id](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-esql-async-query#esql-async-query-api-response-body-query-id) is returned which can be later used to retrieve the results. For example:\n\n```console\nPOST /_query/async\n{\n  \"query\": \"\"\"\n    FROM library\n    | EVAL year = DATE_TRUNC(1 YEARS, release_date)\n    | STATS MAX(page_count) BY year\n    | SORT year\n    | LIMIT 5\n  \"\"\",\n  \"wait_for_completion_timeout\": \"2s\"\n}\n```\n\nIf the results are not available within the given timeout period, 2 seconds in this case, no results are returned but rather a response that includes:\n\n* A query ID\n* An `is_running` value of *true*, indicating the query is ongoing\n\nThe query continues to run in the background without blocking other requests.\n\n```console-result\n{\n  \"id\": \"FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=\",\n  \"is_running\": true\n}\n```\n\nTo check the progress of an async query, use the [{{esql}} async query get API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-esql-async-query-get) with the query ID. Specify how long you\u2019d like to wait for complete results in the `wait_for_completion_timeout` parameter.\n\n```console\nGET /_query/async/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=?wait_for_completion_timeout=30s\n```\n\nIf the response\u2019s `is_running` value is `false`, the query has finished and the results are returned, along with the `took` time for the query.\n\n```console-result\n{\n  \"is_running\": false,\n  \"took\": 48,\n  \"columns\": ...\n}\n```\n\nTo stop a running async query and return the results computed so far, use the [async stop API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-esql-async-query-stop) with the query ID.\n\n```console\nPOST /_query/async/FmNJRUZ1YWZCU3dHY1BIOUhaenVSRkEaaXFlZ3h4c1RTWFNocDdnY2FSaERnUTozNDE=/stop\n```\nThe query will be stopped and the response will contain the results computed so far. The response format is the same as the `get` API.\n\n```console-result\n{\n  \"is_running\": false,\n  \"took\": 48,\n  \"is_partial\": true,\n  \"columns\": ...\n}\n```\nThis API can be used to retrieve results even if the query has already completed, as long as it's within the `keep_alive` window.\nThe `is_partial` field indicates result completeness. A value of `true` means the results are potentially incomplete.\n\nUse the [{{esql}} async query delete API](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-esql-async-query-delete) to delete an async query before the `keep_alive` period ends. If the query is still running, {{es}} cancels it.\n\n```console\nDELETE /_query/async/FmdMX2pIang3UWhLRU5QS0lqdlppYncaMUpYQ05oSkpTc3kwZ21EdC1tbFJXQToxOTI=\n```\n\n::::{note}\nYou will also receive the async ID and running status in the `X-Elasticsearch-Async-Id` and `X-Elasticsearch-Async-Is-Running` HTTP headers of the response, respectively.\nUseful if you use a tabular text format like `txt`, `csv` or `tsv`, as you won't receive those fields in the body there.\n::::",
              "filename": "elasticsearch-main/docs/reference/query-languages/esql/esql-rest.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/specialized-queries.html"
              ],
              "content": "# Specialized queries [specialized-queries]\n\nThis group contains queries which do not fit into the other groups:\n\n[`distance_feature` query](/reference/query-languages/query-dsl/query-dsl-distance-feature-query.md)\n:   A query that computes scores based on the dynamically computed distances between the origin and documents' `date`, `date_nanos`, and `geo_point` fields. It is able to efficiently skip non-competitive hits.\n\n[`more_like_this` query](/reference/query-languages/query-dsl/query-dsl-mlt-query.md)\n:   This query finds documents which are similar to the specified text, document, or collection of documents.\n\n[`percolate` query](/reference/query-languages/query-dsl/query-dsl-percolate-query.md)\n:   This query finds queries that are stored as documents that match with the specified document.\n\n[`rank_feature` query](/reference/query-languages/query-dsl/query-dsl-rank-feature-query.md)\n:   A query that computes scores based on the values of numeric features and is able to efficiently skip non-competitive hits.\n\n[`script` query](/reference/query-languages/query-dsl/query-dsl-script-query.md)\n:   This query allows a script to act as a filter. Also see the [`function_score` query](/reference/query-languages/query-dsl/query-dsl-function-score-query.md).\n\n[`script_score` query](/reference/query-languages/query-dsl/query-dsl-script-score-query.md)\n:   A query that allows to modify the score of a sub-query with a script.\n\n[`wrapper` query](/reference/query-languages/query-dsl/query-dsl-wrapper-query.md)\n:   A query that accepts other queries as json or yaml string.\n\n[`pinned` query](/reference/query-languages/query-dsl/query-dsl-pinned-query.md)\n:   A query that promotes selected documents over others matching a given query.\n\n[`rule` query](/reference/query-languages/query-dsl/query-dsl-rule-query.md)\n:   A query that supports applying query-based contextual rules, defined using the [Query Rules API](https://www.elastic.co/docs/api/doc/elasticsearch/group/endpoint-query_rules), to a given query.",
              "filename": "elasticsearch-main/docs/reference/query-languages/query-dsl/specialized-queries.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html"
              ],
              "content": "# Query and filter context [query-filter-context]\n\n\n## Relevance scores [relevance-scores]\n\nBy default, Elasticsearch sorts matching search results by **relevance score**, which measures how well each document matches a query.\n\nThe relevance score is a positive floating point number, returned in the `_score` metadata field of the [search](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-search) API. The higher the `_score`, the more relevant the document. While each query type can calculate relevance scores differently, score calculation also depends on whether the query clause is run in a **query** or **filter** context.\n\n\n## Query context [query-context]\n\nIn the query context, a query clause answers the question *How well does this document match this query clause?* Besides deciding whether or not the document matches, the query clause also calculates a relevance score in the `_score` metadata field.\n\nQuery context is in effect whenever a query clause is passed to a `query` parameter, such as the `query` parameter in the [search](https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-search#request-body-search-query) API.\n\n\n## Filter context [filter-context]\n\nA filter answers the binary question \u201cDoes this document match this query clause?\u201d. The answer is simply \"yes\" or \"no\". Filtering has several benefits:\n\n1. **Simple binary logic**: In a filter context, a query clause determines document matches based on a yes/no criterion, without score calculation.\n2. **Performance**: Because they don\u2019t compute relevance scores, filters execute faster than queries.\n3. **Caching**: {{es}} automatically caches frequently used filters, speeding up subsequent search performance.\n4. **Resource efficiency**: Filters consume less CPU resources compared to full-text queries.\n5. **Query combination**: Filters can be combined with scored queries to refine result sets efficiently.\n\nFilters are particularly effective for querying structured data and implementing \"must have\" criteria in complex searches.\n\nStructured data refers to information that is highly organized and formatted in a predefined manner. In the context of Elasticsearch, this typically includes:\n\n* Numeric fields (integers, floating-point numbers)\n* Dates and timestamps\n* Boolean values\n* Keyword fields (exact match strings)\n* Geo-points and geo-shapes\n\nUnlike full-text fields, structured data has a consistent, predictable format, making it ideal for precise filtering operations.\n\nCommon filter applications include:\n\n* Date range checks: for example is the `timestamp` field between 2015 and 2016\n* Specific field value checks: for example is the `status` field equal to \"published\" or is the `author` field equal to \"John Doe\"\n\nFilter context applies when a query clause is passed to a `filter` parameter, such as:\n\n* `filter` or `must_not` parameters in [`bool`](/reference/query-languages/query-dsl/query-dsl-bool-query.md)  queries\n* `filter` parameter in [`constant_score`](/reference/query-languages/query-dsl/query-dsl-constant-score-query.md) queries\n* [`filter`](/reference/aggregations/search-aggregations-bucket-filter-aggregation.md) aggregations\n\nFilters optimize query performance and efficiency, especially for structured data queries and when combined with full-text searches.\n\n\n## Example of query and filter contexts [query-filter-context-ex]\n\nBelow is an example of query clauses being used in query and filter context in the `search` API. This query will match documents where all of the following conditions are met:\n\n* The `title` field contains the word `search`.\n* The `content` field contains the word `elasticsearch`.\n* The `status` field contains the exact word `published`.\n* The `publish_date` field contains a date from 1 Jan 2015 onwards.\n\n```console\nGET /_search\n{\n  \"query\": { <1>\n    \"bool\": { <2>\n      \"must\": [\n        { \"match\": { \"title\":   \"Search\"        }},\n        { \"match\": { \"content\": \"Elasticsearch\" }}\n      ],\n      \"filter\": [ <3>\n        { \"term\":  { \"status\": \"published\" }},\n        { \"range\": { \"publish_date\": { \"gte\": \"2015-01-01\" }}}\n      ]\n    }\n  }\n}\n```\n\n1. The `query` parameter indicates query context.\n2. The `bool` and two `match` clauses are used in query context, which means that they are used to score how well each document matches.\n3. The `filter` parameter indicates filter context. Its `term` and `range` clauses are used in filter context. They will filter out documents which do not match, but they will not affect the score for matching documents.\n\n\n::::{warning}\nScores calculated for queries in query context are represented as single precision floating point numbers; they have only 24 bits for significand\u2019s precision. Score calculations that exceed the significand\u2019s precision will be converted to floats with loss of precision.\n::::\n\n\n::::{tip}\nUse query clauses in query context for conditions which should affect the score of matching documents (i.e. how well does the document match), and use all other query clauses in filter context.\n::::",
              "filename": "elasticsearch-main/docs/reference/query-languages/query-dsl/query-filter-context.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html"
              ],
              "applies_to": {
                "stack": "all"
              },
              "content": "# Profile search requests\n\n::::{warning}\nThe Profile API is a debugging tool and adds significant overhead to search execution.\n::::\n\nThe Profile API provides detailed timing information about the execution of individual components in a search request.\nIt gives the user insight into how search requests are executed at a low level so that the user can understand why certain requests are slow, and take steps to improve them.\n\nNote that the Profile API, [amongst other things](search-profile.md#profile-limitations), doesn\u2019t measure network latency, time the requests spend in queues, or time spent merging shard responses on the coordinating node.\n\nThe output from the Profile API is **very** verbose, especially for complicated requests executed across many shards. Pretty-printing the response is recommended to help understand the output.\n\n::::{admonition} New API reference\nFor the most up-to-date API details, refer to [Search APIs](https://www.elastic.co/docs/api/doc/elasticsearch/group/endpoint-search).\n::::\n\nAny `_search` request can be profiled by adding a top-level `profile` parameter:\n\n```console\nGET /my-index-000001/_search\n{\n  \"profile\": true, <1>\n  \"query\" : {\n    \"match\" : { \"message\" : \"GET /search\" }\n  }\n}\n```\n\n1. Setting the top-level `profile` parameter to `true` will enable profiling for the search.\n\n\nThe API returns the following result:\n\n```console-result\n{\n  \"took\": 25,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": {\n      \"value\": 5,\n      \"relation\": \"eq\"\n    },\n    \"max_score\": 0.17402273,\n    \"hits\": [...] <1>\n  },\n  \"profile\": {\n    \"shards\": [\n      {\n        \"id\": \"[q2aE02wS1R8qQFnYu6vDVQ][my-index-000001][0]\",\n        \"node_id\": \"q2aE02wS1R8qQFnYu6vDVQ\",\n        \"shard_id\": 0,\n        \"index\": \"my-index-000001\",\n        \"cluster\": \"(local)\",\n        \"searches\": [\n          {\n            \"query\": [\n              {\n                \"type\": \"BooleanQuery\",\n                \"description\": \"message:get message:search\",\n                \"time_in_nanos\" : 11972972,\n                \"breakdown\" : {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 5,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 39022,\n                  \"match\": 4456,\n                  \"next_doc_count\": 5,\n                  \"score_count\": 5,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 84525,\n                  \"advance_count\": 1,\n                  \"score\": 37779,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 4694895,\n                  \"shallow_advance\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 7112295,\n                  \"count_weight\": 0,\n                  \"count_weight_count\": 0\n                },\n                \"children\": [\n                  {\n                    \"type\": \"TermQuery\",\n                    \"description\": \"message:get\",\n                    \"time_in_nanos\": 3801935,\n                    \"breakdown\": {\n                      \"set_min_competitive_score_count\": 0,\n                      \"match_count\": 0,\n                      \"shallow_advance_count\": 3,\n                      \"set_min_competitive_score\": 0,\n                      \"next_doc\": 0,\n                      \"match\": 0,\n                      \"next_doc_count\": 0,\n                      \"score_count\": 5,\n                      \"compute_max_score_count\": 3,\n                      \"compute_max_score\": 32487,\n                      \"advance\": 5749,\n                      \"advance_count\": 6,\n                      \"score\": 16219,\n                      \"build_scorer_count\": 3,\n                      \"create_weight\": 2382719,\n                      \"shallow_advance\": 9754,\n                      \"create_weight_count\": 1,\n                      \"build_scorer\": 1355007,\n                      \"count_weight\": 0,\n                      \"count_weight_count\": 0\n                    }\n                  },\n                  {\n                    \"type\": \"TermQuery\",\n                    \"description\": \"message:search\",\n                    \"time_in_nanos\": 205654,\n                    \"breakdown\": {\n                      \"set_min_competitive_score_count\": 0,\n                      \"match_count\": 0,\n                      \"shallow_advance_count\": 3,\n                      \"set_min_competitive_score\": 0,\n                      \"next_doc\": 0,\n                      \"match\": 0,\n                      \"next_doc_count\": 0,\n                      \"score_count\": 5,\n                      \"compute_max_score_count\": 3,\n                      \"compute_max_score\": 6678,\n                      \"advance\": 12733,\n                      \"advance_count\": 6,\n                      \"score\": 6627,\n                      \"build_scorer_count\": 3,\n                      \"create_weight\": 130951,\n                      \"shallow_advance\": 2512,\n                      \"create_weight_count\": 1,\n                      \"build_scorer\": 46153,\n                      \"count_weight\": 0,\n                      \"count_weight_count\": 0\n                    }\n                  }\n                ]\n              }\n            ],\n            \"rewrite_time\": 451233,\n            \"collector\": [\n              {\n                \"name\": \"QueryPhaseCollector\",\n                \"reason\": \"search_query_phase\",\n                \"time_in_nanos\": 775274,\n                \"children\" : [\n                  {\n                    \"name\": \"SimpleTopScoreDocCollector\",\n                    \"reason\": \"search_top_hits\",\n                    \"time_in_nanos\": 775274\n                  }\n                ]\n              }\n            ]\n          }\n        ],\n        \"aggregations\": [],\n        \"fetch\": {\n          \"type\": \"fetch\",\n          \"description\": \"\",\n          \"time_in_nanos\": 660555,\n          \"breakdown\": {\n            \"next_reader\": 7292,\n            \"next_reader_count\": 1,\n            \"load_stored_fields\": 299325,\n            \"load_stored_fields_count\": 5,\n            \"load_source\": 3863,\n            \"load_source_count\": 5\n          },\n          \"debug\": {\n            \"stored_fields\": [\"_id\", \"_routing\", \"_source\"]\n          },\n          \"children\": [\n            {\n              \"type\" : \"FetchFieldsPhase\",\n              \"description\" : \"\",\n              \"time_in_nanos\" : 238762,\n              \"breakdown\" : {\n                \"process_count\" : 5,\n                \"process\" : 227914,\n                \"next_reader\" : 10848,\n                \"next_reader_count\" : 1\n              }\n            },\n            {\n              \"type\": \"FetchSourcePhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 20443,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 19698,\n                \"process_count\": 5\n              },\n              \"debug\": {\n                \"fast_path\": 5\n              }\n            },\n            {\n              \"type\": \"StoredFieldsPhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 5310,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 4445,\n                \"process_count\": 5\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n1. Search results are returned, but were omitted here for brevity.\n\n\nEven for a simple query, the response is relatively complicated. Let\u2019s break it down piece-by-piece before moving to more complex examples.\n\nThe overall structure of the profile response is as follows:\n\n```console-result\n{\n   \"profile\": {\n        \"shards\": [\n           {\n              \"id\": \"[q2aE02wS1R8qQFnYu6vDVQ][my-index-000001][0]\",  <1>\n              \"node_id\": \"q2aE02wS1R8qQFnYu6vDVQ\",\n              \"shard_id\": 0,\n              \"index\": \"my-index-000001\",\n              \"cluster\": \"(local)\",             <2>\n              \"searches\": [\n                 {\n                    \"query\": [...],             <3>\n                    \"rewrite_time\": 51443,      <4>\n                    \"collector\": [...]          <5>\n                 }\n              ],\n              \"aggregations\": [...],            <6>\n              \"fetch\": {...}                    <7>\n           }\n        ]\n     }\n}\n```\n\n1. A profile is returned for each shard that participated in the response, and is identified by a unique ID.\n2. If the query was run on the local cluster, the cluster name is left out of the composite id and is marked \"(local)\" here. For a profile running on a remote_cluster using cross-cluster search, the \"id\" value would be something like `[q2aE02wS1R8qQFnYu6vDVQ][remote1:my-index-000001][0]` and the \"cluster\" value would be `remote1`.\n3. Query timings and other debugging information.\n4. The cumulative rewrite time.\n5. Names and invocation timings for each collector.\n6. Aggregation timings, invocation counts, and debug information.\n7. Fetch timing and debug information.\n\n\nBecause a search request may be executed against one or more shards in an index, and a search may cover one or more indices, the top level element in the profile response is an array of `shard` objects. Each shard object lists its `id` which uniquely identifies the shard. The ID\u2019s format is `[nodeID][clusterName:indexName][shardID]`. If the search is run against the local cluster then the clusterName is not added and the format is `[nodeID][indexName][shardID]`.\n\nThe profile itself may consist of one or more \"searches\", where a search is a query executed against the underlying Lucene index. Most search requests submitted by the user will only execute a single `search` against the Lucene index. But occasionally multiple searches will be executed, such as including a global aggregation (which needs to execute a secondary \"match_all\" query for the global context).\n\nInside each `search` object there will be two arrays of profiled information: a `query` array and a `collector` array. Alongside the `search` object is an `aggregations` object that contains the profile information for the aggregations. In the future, more sections may be added, such as `suggest`, `highlight`, etc.\n\nThere will also be a `rewrite` metric showing the total time spent rewriting the query (in nanoseconds).\n\n::::{note}\nAs with other statistics apis, the Profile API supports human readable outputs. This can be turned on by adding `?human=true` to the query string. In this case, the output contains the additional `time` field containing rounded, human readable timing information (e.g. `\"time\": \"391,9ms\"`, `\"time\": \"123.3micros\"`).\n::::\n\n## Profiling queries [profiling-queries]\n\n::::{note}\nThe details provided by the Profile API directly expose Lucene class names and concepts, which means that complete interpretation of the results require fairly advanced knowledge of Lucene. This page attempts to give a crash-course in how Lucene executes queries so that you can use the Profile API to successfully diagnose and debug queries, but it is only an overview. For complete understanding, please refer to Lucene\u2019s documentation and, in places, the code.\n\nWith that said, a complete understanding is often not required to fix a slow query. It is usually sufficient to see that a particular component of a query is slow, and not necessarily understand why the `advance` phase of that query is the cause, for example.\n\n::::\n\n\n### Query section [query-section]\n\nThe `query` section contains detailed timing of the query tree executed by Lucene on a particular shard. The overall structure of this query tree will resemble your original Elasticsearch query, but may be slightly (or sometimes very) different. It will also use similar but not always identical naming. Using our previous `match` query example, let\u2019s analyze the `query` section:\n\n```console-result\n\"query\": [\n    {\n       \"type\": \"BooleanQuery\",\n       \"description\": \"message:get message:search\",\n       \"time_in_nanos\": \"11972972\",\n       \"breakdown\": {...},               <1>\n       \"children\": [\n          {\n             \"type\": \"TermQuery\",\n             \"description\": \"message:get\",\n             \"time_in_nanos\": \"3801935\",\n             \"breakdown\": {...}\n          },\n          {\n             \"type\": \"TermQuery\",\n             \"description\": \"message:search\",\n             \"time_in_nanos\": \"205654\",\n             \"breakdown\": {...}\n          }\n       ]\n    }\n]\n```\n\n1. The breakdown timings are omitted for simplicity.\n\n\nBased on the profile structure, we can see that our `match` query was rewritten by Lucene into a BooleanQuery with two clauses (both holding a TermQuery). The `type` field displays the Lucene class name, and often aligns with the equivalent name in Elasticsearch. The `description` field displays the Lucene explanation text for the query, and is made available to help differentiating between parts of your query (e.g. both `message:get` and `message:search` are TermQuery\u2019s and would appear identical otherwise.\n\nThe `time_in_nanos` field shows that this query took ~11.9ms for the entire BooleanQuery to execute. The recorded time is inclusive of all children.\n\nThe `breakdown` field will give detailed stats about how the time was spent, we\u2019ll look at that in a moment. Finally, the `children` array lists any sub-queries that may be present. Because we searched for two values (\"get search\"), our BooleanQuery holds two children TermQueries. They have identical information (type, time, breakdown, etc). Children are allowed to have their own children.\n\n\n### Timing breakdown [_timing_breakdown]\n\nThe `breakdown` component lists detailed timing statistics about low-level Lucene execution:\n\n```console-result\n\"breakdown\": {\n  \"set_min_competitive_score_count\": 0,\n  \"match_count\": 5,\n  \"shallow_advance_count\": 0,\n  \"set_min_competitive_score\": 0,\n  \"next_doc\": 39022,\n  \"match\": 4456,\n  \"next_doc_count\": 5,\n  \"score_count\": 5,\n  \"compute_max_score_count\": 0,\n  \"compute_max_score\": 0,\n  \"advance\": 84525,\n  \"advance_count\": 1,\n  \"score\": 37779,\n  \"build_scorer_count\": 2,\n  \"create_weight\": 4694895,\n  \"shallow_advance\": 0,\n  \"create_weight_count\": 1,\n  \"build_scorer\": 7112295,\n  \"count_weight\": 0,\n  \"count_weight_count\": 0\n}\n```\n\nTimings are listed in wall-clock nanoseconds and are not normalized at all. All caveats about the overall `time_in_nanos` apply here. The intention of the breakdown is to give you a feel for A) what machinery in Lucene is actually eating time, and B) the magnitude of differences in times between the various components. Like the overall time, the breakdown is inclusive of all children times.\n\nThe meaning of the stats are as follows:\n\n\n#### All parameters [_all_parameters]\n\n`create_weight`\n:   A Query in Lucene must be capable of reuse across multiple IndexSearchers (think of it as the engine that executes a search against a specific Lucene Index). This puts Lucene in a tricky spot, since many queries need to accumulate temporary state/statistics associated with the index it is being used against, but the Query contract mandates that it must be immutable. <br> <br> To get around this, Lucene asks each query to generate a Weight object which acts as a temporary context object to hold state associated with this particular (IndexSearcher, Query) tuple. The `weight` metric shows how long this process takes\n\n`build_scorer`\n:   This parameter shows how long it takes to build a Scorer for the query. A Scorer is the mechanism that iterates over matching documents and generates a score per-document (e.g. how well does \"foo\" match the document?). Note, this records the time required to generate the Scorer object, not actually score the documents. Some queries have faster or slower initialization of the Scorer, depending on optimizations, complexity, etc. This may also show timing associated with caching, if enabled and/or applicable for the query\n\n`next_doc`\n:   The Lucene method `next_doc` returns Doc ID of the next document matching the query. This statistic shows the time it takes to determine which document is the next match, a process that varies considerably depending on the nature of the query. Next_doc is a specialized form of advance() which is more convenient for many queries in Lucene. It is equivalent to advance(docId() + 1)\n\n`advance`\n:   `advance` is the \"lower level\" version of next_doc: it serves the same purpose of finding the next matching doc, but requires the calling query to perform extra tasks such as identifying and moving past skips, etc. However,  not all queries can use next_doc, so `advance` is also timed for those queries. <br> <br> Conjunctions (e.g. `must` clauses in a Boolean) are typical consumers of `advance`\n\n`match`\n:   Some queries, such as phrase queries, match documents using a \"two-phase\" process. First, the document is \"approximately\" matched, and if it matches approximately, it is checked a second time with a more rigorous (and expensive) process. The second phase verification is what the `match` statistic measures. <br> <br> For example, a phrase query first checks a document approximately by ensuring all terms in the phrase are present in the doc. If all the terms are present, it then executes the second phase verification to ensure the terms are in-order to form the phrase, which is relatively more expensive than just checking for presence of the terms. <br> <br> Because this two-phase process is only used by a handful of queries, the `match` statistic is often zero\n\n`score`\n:   This records the time taken to score a particular document via its Scorer\n\n`*_count`\n:   Records the number of invocations of the particular method. For example, `\"next_doc_count\": 2,` means the `nextDoc()` method was called on two different documents. This can be used to help judge how selective queries are, by comparing counts between different query components.\n\n\n### Collectors section [collectors-section]\n\nThe Collectors portion of the response shows high-level execution details. Lucene works by defining a \"Collector\" which is responsible for coordinating the traversal, scoring, and collection of matching documents. Collectors are also how a single query can record aggregation results, execute unscoped \"global\" queries, execute post-query filters, etc.\n\nLooking at the previous example:\n\n```console-result\n\"collector\": [\n  {\n    \"name\": \"QueryPhaseCollector\",\n    \"reason\": \"search_query_phase\",\n    \"time_in_nanos\": 775274,\n    \"children\" : [\n      {\n        \"name\": \"SimpleTopScoreDocCollector\",\n        \"reason\": \"search_top_hits\",\n        \"time_in_nanos\": 775274\n      }\n    ]\n  }\n]\n```\n\nWe see a top-level collector named `QueryPhaseCollector` which holds a child `SimpleTopScoreDocCollector`. `SimpleTopScoreDocCollector` is the  default \"scoring and sorting\" `Collector` used by {{es}}. The `reason` field attempts to give a plain English description of the class name. The `time_in_nanos` is similar to the time in the Query tree: a wall-clock time inclusive of all children. Similarly, `children` lists all sub-collectors. When aggregations are requested, the `QueryPhaseCollector` will hold an additional child collector with reason `aggregation` that is the one performing aggregations.\n\nIt should be noted that Collector times are **independent** from the Query times. They are calculated, combined, and normalized independently! Due to the nature of Lucene\u2019s execution, it is impossible to \"merge\" the times from the Collectors into the Query section, so they are displayed in separate portions.\n\nFor reference, the various collector reasons are:\n\n`search_top_hits`\n:   A collector that scores and sorts documents. This is the most common collector and will be seen in most simple searches\n\n`search_count`\n:   A collector that only counts the number of documents that match the query, but does not fetch the source. This is seen when `size: 0` is specified\n\n`search_query_phase`\n:   A collector that incorporates collecting top hits as well aggregations as part of the query phase. It supports terminating the search execution after `n` matching documents have been found (when `terminate_after` is specified), as well as only returning matching documents that have a score greater than `n` (when `min_score` is provided). Additionally, it is able to filter matching top hits based on the provided `post_filter`.\n\n`search_timeout`\n:   A collector that halts execution after a specified period of time. This is seen when a `timeout` top-level parameter has been specified.\n\n`aggregation`\n:   A collector that Elasticsearch uses to run aggregations against the query scope. A single `aggregation` collector is used to collect documents for **all** aggregations, so you will see a list of aggregations in the name rather.\n\n`global_aggregation`\n:   A collector that executes an aggregation against the global query scope, rather than the specified query. Because the global scope is necessarily different from the executed query, it must execute its own match_all query (which you will see added to the Query section) to collect your entire dataset\n\n\n### Rewrite section [rewrite-section]\n\nAll queries in Lucene undergo a \"rewriting\" process. A query (and its sub-queries) may be rewritten one or more times, and the process continues until the query stops changing. This process allows Lucene to perform optimizations, such as removing redundant clauses, replacing one query for a more efficient execution path, etc. For example a Boolean \u2192 Boolean \u2192 TermQuery can be rewritten to a TermQuery, because all the Booleans are unnecessary in this case.\n\nThe rewriting process is complex and difficult to display, since queries can change drastically. Rather than showing the intermediate results, the total rewrite time is simply displayed as a value (in nanoseconds). This value is cumulative and contains the total time for all queries being rewritten.\n\n\n### A more complex example [_a_more_complex_example]\n\nTo demonstrate a slightly more complex query and the associated results, we can profile the following query:\n\n```console\nGET /my-index-000001/_search\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"my_scoped_agg\": {\n      \"terms\": {\n        \"field\": \"http.response.status_code\"\n      }\n    },\n    \"my_global_agg\": {\n      \"global\": {},\n      \"aggs\": {\n        \"my_level_agg\": {\n          \"terms\": {\n            \"field\": \"http.response.status_code\"\n          }\n        }\n      }\n    }\n  },\n  \"post_filter\": {\n    \"match\": {\n      \"message\": \"search\"\n    }\n  }\n}\n```\n\nThis example has:\n\n* A query\n* A scoped aggregation\n* A global aggregation\n* A post_filter\n\nThe API returns the following result:\n\n```console-result\n{\n  ...\n  \"profile\": {\n    \"shards\": [\n      {\n        \"id\": \"[P6xvulHtQRWuD4YnubWb7A][my-index-000001][0]\",\n        \"node_id\": \"P6xvulHtQRWuD4YnubWb7A\",\n        \"shard_id\": 0,\n        \"index\": \"my-index-000001\",\n        \"cluster\": \"(local)\",\n        \"searches\": [\n          {\n            \"query\": [\n              {\n                \"type\": \"TermQuery\",\n                \"description\": \"message:search\",\n                \"time_in_nanos\": 141618,\n                \"breakdown\": {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 0,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 0,\n                  \"match\": 0,\n                  \"next_doc_count\": 0,\n                  \"score_count\": 0,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 3942,\n                  \"advance_count\": 4,\n                  \"count_weight_count\": 0,\n                  \"score\": 0,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 38380,\n                  \"shallow_advance\": 0,\n                  \"count_weight\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 99296\n                }\n              },\n              {\n                \"type\": \"TermQuery\",\n                \"description\": \"user.id:elkbee\",\n                \"time_in_nanos\": 163081,\n                \"breakdown\": {\n                  \"set_min_competitive_score_count\": 0,\n                  \"match_count\": 0,\n                  \"shallow_advance_count\": 0,\n                  \"set_min_competitive_score\": 0,\n                  \"next_doc\": 2447,\n                  \"match\": 0,\n                  \"next_doc_count\": 4,\n                  \"score_count\": 4,\n                  \"compute_max_score_count\": 0,\n                  \"compute_max_score\": 0,\n                  \"advance\": 3552,\n                  \"advance_count\": 1,\n                  \"score\": 5027,\n                  \"count_weight_count\": 0,\n                  \"build_scorer_count\": 2,\n                  \"create_weight\": 107840,\n                  \"shallow_advance\": 0,\n                  \"count_weight\": 0,\n                  \"create_weight_count\": 1,\n                  \"build_scorer\": 44215\n                }\n              }\n            ],\n            \"rewrite_time\": 4769,\n            \"collector\": [\n              {\n                \"name\": \"QueryPhaseCollector\",\n                \"reason\": \"search_query_phase\",\n                \"time_in_nanos\": 1945072,\n                \"children\": [\n                  {\n                    \"name\": \"SimpleTopScoreDocCollector\",\n                    \"reason\": \"search_top_hits\",\n                    \"time_in_nanos\": 22577\n                  },\n                  {\n                    \"name\": \"AggregatorCollector: [my_scoped_agg, my_global_agg]\",\n                    \"reason\": \"aggregation\",\n                    \"time_in_nanos\": 867617\n                  }\n                ]\n              }\n            ]\n          }\n        ],\n        \"aggregations\": [...], <1>\n        \"fetch\": {...}\n      }\n    ]\n  }\n}\n```\n\n1. The `\"aggregations\"` portion has been omitted because it will be covered in the next section.\n\n\nAs you can see, the output is significantly more verbose than before. All the major portions of the query are represented:\n\n1. The first `TermQuery` (user.id:elkbee) represents the main `term` query.\n2. The second `TermQuery` (message:search) represents the `post_filter` query.\n\nThe Collector tree is fairly straightforward, showing how a single QueryPhaseCollector that holds the normal scoring SimpleTopScoreDocCollector used to collect top hits, as well as BucketCollectorWrapper to run all scoped aggregations.\n\n\n### Understanding MultiTermQuery output [_understanding_multitermquery_output]\n\nA special note needs to be made about the `MultiTermQuery` class of queries. This includes wildcards, regex, and fuzzy queries. These queries emit very verbose responses, and are not overly structured.\n\nEssentially, these queries rewrite themselves on a per-segment basis. If you imagine the wildcard query `b*`, it technically can match any token that begins with the letter \"b\". It would be impossible to enumerate all possible combinations, so Lucene rewrites the query in context of the segment being evaluated, e.g., one segment may contain the tokens `[bar, baz]`, so the query rewrites to a BooleanQuery combination of \"bar\" and \"baz\". Another segment may only have the token `[bakery]`, so the query rewrites to a single TermQuery for \"bakery\".\n\nDue to this dynamic, per-segment rewriting, the clean tree structure becomes distorted and no longer follows a clean \"lineage\" showing how one query rewrites into the next. At present time, all we can do is apologize, and suggest you collapse the details for that query\u2019s children if it is too confusing. Luckily, all the timing statistics are correct, just not the physical layout in the response, so it is sufficient to just analyze the top-level MultiTermQuery and ignore its children if you find the details too tricky to interpret.\n\nHopefully this will be fixed in future iterations, but it is a tricky problem to solve and still in-progress. :)\n\n\n### Profiling aggregations [profiling-aggregations]\n\n#### Aggregations section [agg-section]\n\nThe `aggregations` section contains detailed timing of the aggregation tree executed by a particular shard. The overall structure of this aggregation tree will resemble your original {{es}} request. Let\u2019s execute the previous query again and look at the aggregation profile this time:\n\n```console\nGET /my-index-000001/_search\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"my_scoped_agg\": {\n      \"terms\": {\n        \"field\": \"http.response.status_code\"\n      }\n    },\n    \"my_global_agg\": {\n      \"global\": {},\n      \"aggs\": {\n        \"my_level_agg\": {\n          \"terms\": {\n            \"field\": \"http.response.status_code\"\n          }\n        }\n      }\n    }\n  },\n  \"post_filter\": {\n    \"match\": {\n      \"message\": \"search\"\n    }\n  }\n}\n```\n\nThis yields the following aggregation profile output:\n\n```console-result\n{\n  \"profile\": {\n    \"shards\": [\n      {\n        \"aggregations\": [\n          {\n            \"type\": \"NumericTermsAggregator\",\n            \"description\": \"my_scoped_agg\",\n            \"time_in_nanos\": 79294,\n            \"breakdown\": {\n              \"reduce\": 0,\n              \"build_aggregation\": 30885,\n              \"build_aggregation_count\": 1,\n              \"initialize\": 2623,\n              \"initialize_count\": 1,\n              \"reduce_count\": 0,\n              \"collect\": 45786,\n              \"collect_count\": 4,\n              \"build_leaf_collector\": 18211,\n              \"build_leaf_collector_count\": 1,\n              \"post_collection\": 929,\n              \"post_collection_count\": 1\n            },\n            \"debug\": {\n              \"total_buckets\": 1,\n              \"result_strategy\": \"long_terms\",\n              \"built_buckets\": 1\n            }\n          },\n          {\n            \"type\": \"GlobalAggregator\",\n            \"description\": \"my_global_agg\",\n            \"time_in_nanos\": 104325,\n            \"breakdown\": {\n              \"reduce\": 0,\n              \"build_aggregation\": 22470,\n              \"build_aggregation_count\": 1,\n              \"initialize\": 12454,\n              \"initialize_count\": 1,\n              \"reduce_count\": 0,\n              \"collect\": 69401,\n              \"collect_count\": 4,\n              \"build_leaf_collector\": 8150,\n              \"build_leaf_collector_count\": 1,\n              \"post_collection\": 1584,\n              \"post_collection_count\": 1\n            },\n            \"debug\": {\n              \"built_buckets\": 1\n            },\n            \"children\": [\n              {\n                \"type\": \"NumericTermsAggregator\",\n                \"description\": \"my_level_agg\",\n                \"time_in_nanos\": 76876,\n                \"breakdown\": {\n                  \"reduce\": 0,\n                  \"build_aggregation\": 13824,\n                  \"build_aggregation_count\": 1,\n                  \"initialize\": 1441,\n                  \"initialize_count\": 1,\n                  \"reduce_count\": 0,\n                  \"collect\": 61611,\n                  \"collect_count\": 4,\n                  \"build_leaf_collector\": 5564,\n                  \"build_leaf_collector_count\": 1,\n                  \"post_collection\": 471,\n                  \"post_collection_count\": 1\n                },\n                \"debug\": {\n                  \"total_buckets\": 1,\n                  \"result_strategy\": \"long_terms\",\n                  \"built_buckets\": 1\n                }\n              }\n            ]\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\nFrom the profile structure we can see that the `my_scoped_agg` is internally being run as a `NumericTermsAggregator` (because the field it is aggregating, `http.response.status_code`, is a numeric field). At the same level, we see a `GlobalAggregator` which comes from `my_global_agg`. That aggregation then has a child `NumericTermsAggregator` which comes from the second term\u2019s aggregation on `http.response.status_code`.\n\nThe `time_in_nanos` field shows the time executed by each aggregation, and is inclusive of all children. While the overall time is useful, the `breakdown` field will give detailed stats about how the time was spent.\n\nSome aggregations may return expert `debug` information that describe features of the underlying execution of the aggregation that are 'useful for folks that hack on aggregations but that we don\u2019t expect to be otherwise useful. They can vary wildly between versions, aggregations, and aggregation execution strategies.\n\n### Timing breakdown [_timing_breakdown_2]\n\nThe `breakdown` component lists detailed statistics about low-level execution:\n\n```js\n\"breakdown\": {\n  \"reduce\": 0,\n  \"build_aggregation\": 30885,\n  \"build_aggregation_count\": 1,\n  \"initialize\": 2623,\n  \"initialize_count\": 1,\n  \"reduce_count\": 0,\n  \"collect\": 45786,\n  \"collect_count\": 4,\n  \"build_leaf_collector\": 18211,\n  \"build_leaf_collector_count\": 1\n}\n```\n\nEach property in the `breakdown` component corresponds to an internal method for the aggregation. For example, the `build_leaf_collector` property measures nanoseconds spent running the aggregation\u2019s `getLeafCollector()` method. Properties ending in `_count` record the number of invocations of the particular method. For example, `\"collect_count\": 2` means the aggregation called the `collect()` on two different documents. The `reduce` property is reserved for future use and always returns `0`.\n\nTimings are listed in wall-clock nanoseconds and are not normalized at all. All caveats about the overall `time` apply here. The intention of the breakdown is to give you a feel for A) what machinery in {{es}} is actually eating time, and B) the magnitude of differences in times between the various components. Like the overall time, the breakdown is inclusive of all children times.\n\n\n### Profiling fetch [profiling-fetch]\n\nAll shards that fetched documents will have a `fetch` section in the profile. Let\u2019s execute a small search and have a look at the fetch profile:\n\n```console\nGET /my-index-000001/_search?filter_path=profile.shards.fetch\n{\n  \"profile\": true,\n  \"query\": {\n    \"term\": {\n      \"user.id\": {\n        \"value\": \"elkbee\"\n      }\n    }\n  }\n}\n```\n\nAnd here is the fetch profile:\n\n```console-result\n{\n  \"profile\": {\n    \"shards\": [\n      {\n        \"fetch\": {\n          \"type\": \"fetch\",\n          \"description\": \"\",\n          \"time_in_nanos\": 660555,\n          \"breakdown\": {\n            \"next_reader\": 7292,\n            \"next_reader_count\": 1,\n            \"load_stored_fields\": 299325,\n            \"load_stored_fields_count\": 5,\n            \"load_source\": 3863,\n            \"load_source_count\": 5\n          },\n          \"debug\": {\n            \"stored_fields\": [\"_id\", \"_routing\", \"_source\"]\n          },\n          \"children\": [\n            {\n              \"type\" : \"FetchFieldsPhase\",\n              \"description\" : \"\",\n              \"time_in_nanos\" : 238762,\n              \"breakdown\" : {\n                \"process_count\" : 5,\n                \"process\" : 227914,\n                \"next_reader\" : 10848,\n                \"next_reader_count\" : 1\n              }\n            },\n            {\n              \"type\": \"FetchSourcePhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 20443,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 19698,\n                \"process_count\": 5\n              },\n              \"debug\": {\n                \"fast_path\": 4\n              }\n            },\n            {\n              \"type\": \"StoredFieldsPhase\",\n              \"description\": \"\",\n              \"time_in_nanos\": 5310,\n              \"breakdown\": {\n                \"next_reader\": 745,\n                \"next_reader_count\": 1,\n                \"process\": 4445,\n                \"process_count\": 5\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\nSince this is debugging information about the way that Elasticsearch executes the fetch it can change from request to request and version to version. Even patch versions may change the output here. That lack of consistency is what makes it useful for debugging.\n\nAnyway! `time_in_nanos` measures the time total time of the fetch phase. The `breakdown` counts and times the our per-segment preparation in `next_reader` and the time taken loading stored fields in `load_stored_fields`. Debug contains miscellaneous non-timing information, specifically `stored_fields` lists the stored fields that fetch will have to load. If it is an empty list then fetch will entirely skip loading stored fields.\n\nThe `children` section lists the sub-phases that do the actual fetching work and the `breakdown` has counts and timings for the per-segment preparation in `next_reader` and the per document fetching in `process`.\n\n::::{note}\nWe try hard to load all of the stored fields that we will need for the fetch up front. This tends to make the `_source` phase a couple of microseconds per hit. In that case the true cost of `_source` phase is hidden in the `load_stored_fields` component of the breakdown. It\u2019s possible to entirely skip loading stored fields by setting `\"_source\": false, \"stored_fields\": [\"_none_\"]`.\n::::\n\n\n\n### Profiling DFS [profiling-dfs]\n\nThe DFS phase runs before the query phase to collect global information relevant to the query. It\u2019s currently used in two cases:\n\n1. When the `search_type` is set to [`dfs_query_then_fetch`](search-profile.md#profiling-dfs-statistics) and the index has multiple shards.\n2. When the search request contains a [knn section](search-profile.md#profiling-knn-search).\n\nBoth of these cases can be profiled by setting `profile` to `true` as part of the search request.\n\n#### Profiling DFS statistics [profiling-dfs-statistics]\n\nWhen the `search_type` is set to `dfs_query_then_fetch` and the index has multiple shards, the dfs phase collects term statistics to improve the relevance of search results.\n\nThe following is an example of setting `profile` to `true` on a search that uses `dfs_query_then_fetch`:\n\nLet\u2019s first setup an index with multiple shards and index a pair of documents with different values on a `keyword` field.\n\n$$$profile_dfs$$$\n\n```console\nPUT my-dfs-index\n{\n  \"settings\": {\n    \"number_of_shards\": 2, <1>\n    \"number_of_replicas\": 1\n  },\n  \"mappings\": {\n      \"properties\": {\n        \"my-keyword\": { \"type\": \"keyword\" }\n      }\n    }\n}\n\nPOST my-dfs-index/_bulk?refresh=true\n{ \"index\" : { \"_id\" : \"1\" } }\n{ \"my-keyword\" : \"a\" }\n{ \"index\" : { \"_id\" : \"2\" } }\n{ \"my-keyword\" : \"b\" }\n```\n\n1. The `my-dfs-index` is created with multiple shards.\n\n\nWith an index setup, we can now profile the dfs phase of a search query. For this example we use a term query.\n\n```console\nGET /my-dfs-index/_search?search_type=dfs_query_then_fetch&pretty&size=0 <1>\n{\n  \"profile\": true, <2>\n  \"query\": {\n    \"term\": {\n      \"my-keyword\": {\n        \"value\": \"a\"\n      }\n    }\n  }\n}\n```\n\n1. The `search_type` url parameter is set to `dfs_query_then_fetch` to ensure the dfs phase is run.\n2. The `profile` parameter is set to `true`.\n\n\nIn the response, we see a profile which includes a `dfs` section for each shard along with profile output for the rest of the search phases. One of the `dfs` sections for a shard looks like the following:\n\n```console-result\n\"dfs\" : {\n    \"statistics\" : {\n        \"type\" : \"statistics\",\n        \"description\" : \"collect term statistics\",\n        \"time_in_nanos\" : 236955,\n        \"breakdown\" : {\n            \"term_statistics\" : 4815,\n            \"collection_statistics\" : 27081,\n            \"collection_statistics_count\" : 1,\n            \"create_weight\" : 153278,\n            \"term_statistics_count\" : 1,\n            \"rewrite_count\" : 0,\n            \"create_weight_count\" : 1,\n            \"rewrite\" : 0\n        }\n    }\n}\n```\n\nIn the `dfs.statistics` portion of this response we see a `time_in_nanos` which is the total time it took to collect term statistics for this shard along with a further breakdown of the individual parts.\n\n\n#### Profiling kNN search [profiling-knn-search]\n\nA k-nearest neighbor (kNN) search runs during the dfs phase.\n\nThe following is an example of setting `profile` to `true` on a search that has a `knn` section:\n\nLet\u2019s first setup an index with several dense vectors.\n\n$$$profile_knn$$$\n\n```console\nPUT my-knn-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"my-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"index\": true,\n        \"similarity\": \"l2_norm\"\n      }\n    }\n  }\n}\n\nPOST my-knn-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"my-vector\": [1, 5, -20] }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"my-vector\": [42, 8, -15] }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"my-vector\": [15, 11, 23] }\n```\n\nWith an index setup, we can now profile a kNN search query.\n\n```console\nPOST my-knn-index/_search\n{\n  \"profile\": true, <1>\n  \"knn\": {\n    \"field\": \"my-vector\",\n    \"query_vector\": [-5, 9, -12],\n    \"k\": 3,\n    \"num_candidates\": 100\n  }\n}\n```\n\n1. The `profile` parameter is set to `true`.\n\n\nIn the response, we see a profile which includes a `knn` section as part of the `dfs` section for each shard along with profile output for the rest of the search phases.\n\nOne of the `dfs.knn` sections for a shard looks like the following:\n\n```js\n\"dfs\" : {\n    \"knn\" : [\n        {\n        \"vector_operations_count\" : 4,\n        \"query\" : [\n            {\n                \"type\" : \"DocAndScoreQuery\",\n                \"description\" : \"DocAndScoreQuery[0,...][0.008961825,...],0.008961825\",\n                \"time_in_nanos\" : 444414,\n                \"breakdown\" : {\n                  \"set_min_competitive_score_count\" : 0,\n                  \"match_count\" : 0,\n                  \"shallow_advance_count\" : 0,\n                  \"set_min_competitive_score\" : 0,\n                  \"next_doc\" : 1688,\n                  \"match\" : 0,\n                  \"next_doc_count\" : 3,\n                  \"score_count\" : 3,\n                  \"compute_max_score_count\" : 0,\n                  \"compute_max_score\" : 0,\n                  \"advance\" : 4153,\n                  \"advance_count\" : 1,\n                  \"score\" : 2099,\n                  \"build_scorer_count\" : 2,\n                  \"create_weight\" : 128879,\n                  \"shallow_advance\" : 0,\n                  \"create_weight_count\" : 1,\n                  \"build_scorer\" : 307595,\n                  \"count_weight\": 0,\n                  \"count_weight_count\": 0\n                }\n            }\n        ],\n        \"rewrite_time\" : 1275732,\n        \"collector\" : [\n            {\n                \"name\" : \"SimpleTopScoreDocCollector\",\n                \"reason\" : \"search_top_hits\",\n                \"time_in_nanos\" : 17163\n            }\n        ]\n    }   ]\n}\n```\n\nIn the `dfs.knn` portion of the response we can see the output the of timings for [query](search-profile.md#query-section), [rewrite](search-profile.md#rewrite-section), and [collector](search-profile.md#collectors-section). Unlike many other queries, kNN search does the bulk of the work during the query rewrite. This means `rewrite_time` represents the time spent on kNN search. The attribute `vector_operations_count` represents the overall count of vector operations performed during the kNN search.\n\n\n\n### Profiling considerations [profiling-considerations]\n\nLike any profiler, the Profile API introduces a non-negligible overhead to search execution. The act of instrumenting low-level method calls such as `collect`, `advance`, and `next_doc` can be fairly expensive, since these methods are called in tight loops. Therefore, profiling should not be enabled in production settings by default, and should not be compared against non-profiled query times. Profiling is just a diagnostic tool.\n\nThere are also cases where special Lucene optimizations are disabled, since they are not amenable to profiling. This could cause some queries to report larger relative times than their non-profiled counterparts, but in general should not have a drastic effect compared to other components in the profiled query.\n\n\n### Limitations [profile-limitations]\n\n* Profiling currently does not measure the network overhead.\n* Profiling also does not account for time spent in the queue, merging shard responses on the coordinating node, or additional work such as building global ordinals (an internal data structure used to speed up search).\n* Profiling statistics are currently not available for suggestions.\n* Profiling of the reduce phase of aggregation is currently not available.\n* The Profiler is instrumenting internals that can change from version to version. The resulting json should be considered mostly unstable, especially things in the `debug` section.",
              "filename": "elasticsearch-main/docs/reference/elasticsearch/rest-apis/search-profile.md"
            }
          ],
          "tool_call_id": "call_rTaHD0Cs5sKN9qOVqV55O7Qn",
          "metadata": null,
          "timestamp": "2025-10-03T04:05:12.601461+00:00",
          "part_kind": "tool-return"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "content": "The Elastic Search PHP client is significant for several reasons that relate to structuring queries effectively:\n\n1. **Abstraction and Ease of Use**: The PHP client provides a high-level abstraction over the Elasticsearch REST API, allowing PHP developers to construct and execute queries without dealing directly with the low-level HTTP requests and responses. This abstraction simplifies the interaction with Elasticsearch and makes it easier to implement complex queries.\n\n2. **Query DSL Integration**: The Elastic Search PHP client supports Elasticsearch\u2019s powerful Query DSL. Developers can leverage this DSL to write structured queries using PHP syntax, making it straightforward to incorporate complex querying capabilities such as full-text search, filters, and aggregations. For example, developers can create `match`, `multi_match`, and other query types in a programmatic way, which enhances readability and maintainability of the code.\n\n3. **Performance and Profiling**: The client allows developers to take advantage of Elasticsearch's performance features, such as query profiling. By profiling queries, developers can gain insights into execution times and optimize their searches effectively. Profiling can help to identify bottlenecks, allowing for more efficient query structuring and execution ([source](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html)).\n\n4. **Handling Complex Queries**: Through the PHP client, users can build complex queries that combine both query and filter contexts. This is particularly useful for optimizing search performance. The client makes it easy to switch between query contexts (which involve scoring) and filter contexts (which don't), allowing developers to structure their queries in a way that balances accuracy with performance ([source](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html)).\n\n5. **Support for Advanced Features**: The Elastic Search PHP client allows direct access to specialized queries and features like aggregations and scripting, enabling developers to create sophisticated search solutions tailored to specific use cases.\n\nIn summary, the Elastic Search PHP client is a crucial tool that enhances how queries are structured and executed in Elasticsearch, thereby improving development efficiency and application performance. The integration with PHP and support for Elasticsearch features allow for the creation of tailored, effective search functionalities within applications.\n\nFor further information on using the Elastic Search PHP client, you can refer to the [Elasticsearch PHP Client documentation](https://www.elastic.co/guide/en/elasticsearch/client/php-api/current/index.html).",
          "id": null,
          "part_kind": "text"
        }
      ],
      "usage": {
        "input_tokens": 19651,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 475,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T04:05:12+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "stop"
      },
      "provider_response_id": "chatcmpl-CMRKaRg4GLcTp2TdJR4Yc4fItryCn",
      "finish_reason": "stop"
    }
  ],
  "source": "ai-generated"
}