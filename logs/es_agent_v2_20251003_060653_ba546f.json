{
  "agent_name": "es_agent_v2",
  "system_prompt": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "tools": [
    "search"
  ],
  "messages": [
    {
      "parts": [
        {
          "content": "What is the purpose of the `hindi_keywords` filter in Hindi text analysis within Elastic Search?",
          "timestamp": "2025-10-03T06:06:49.229451+00:00",
          "part_kind": "user-prompt"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "args": "{\"query\":\"hindi_keywords filter\"}",
          "tool_call_id": "call_Hi9WYxjyMDF4orrx9fTT1dBt",
          "part_kind": "tool-call"
        }
      ],
      "usage": {
        "input_tokens": 221,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 16,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T06:06:49+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "tool_calls"
      },
      "provider_response_id": "chatcmpl-CMTEHlULJgCv7rknHXoiJja0KsZcV",
      "finish_reason": "tool_call"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "content": [
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-keywords.html"
              ],
              "products": [
                {
                  "id": "painless"
                }
              ],
              "content": "# Keywords [painless-keywords]\n\nKeywords are reserved tokens for built-in language features.\n\n**Errors**\n\n* If a keyword is used as an [identifier](/reference/scripting-languages/painless/painless-identifiers.md).\n\n**Keywords**\n\n|     |     |     |     |     |\n| --- | --- | --- | --- | --- |\n| if | else | while | do | for |\n| in | continue | break | return | new |\n| try | catch | throw | this | instanceof |",
              "filename": "elasticsearch-main/docs/reference/scripting-languages/painless/painless-keywords.md"
            },
            {
              "content": "# Reference",
              "filename": "elasticsearch-main/docs/reference/index.md"
            },
            {
              "content": "* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`CHANGE_POINT`](/reference/query-languages/esql/commands/change-point.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`COMPLETION`](/reference/query-languages/esql/commands/completion.md)\n* [`DISSECT`](/reference/query-languages/esql/commands/dissect.md)\n* [`DROP`](/reference/query-languages/esql/commands/drop.md)\n* [`ENRICH`](/reference/query-languages/esql/commands/enrich.md)\n* [`EVAL`](/reference/query-languages/esql/commands/eval.md)\n* [`GROK`](/reference/query-languages/esql/commands/grok.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`FORK`](/reference/query-languages/esql/commands/fork.md)\n* [`KEEP`](/reference/query-languages/esql/commands/keep.md)\n* [`LIMIT`](/reference/query-languages/esql/commands/limit.md)\n* [`LOOKUP JOIN`](/reference/query-languages/esql/commands/lookup-join.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`INLINE STATS`](/reference/query-languages/esql/commands/inlinestats-by.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`MV_EXPAND`](/reference/query-languages/esql/commands/mv_expand.md)\n* [`RENAME`](/reference/query-languages/esql/commands/rename.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`RERANK`](/reference/query-languages/esql/commands/rerank.md)\n* {applies_to}`stack: preview` {applies_to}`serverless: preview` [`SAMPLE`](/reference/query-languages/esql/commands/sample.md)\n* [`SORT`](/reference/query-languages/esql/commands/sort.md)\n* [`STATS`](/reference/query-languages/esql/commands/stats-by.md)\n* [`WHERE`](/reference/query-languages/esql/commands/where.md)",
              "filename": "elasticsearch-main/docs/reference/query-languages/esql/_snippets/lists/processing-commands.md"
            },
            {
              "navigation_title": "Match boolean prefix",
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-bool-prefix-query.html"
              ],
              "content": "# Match boolean prefix query [query-dsl-match-bool-prefix-query]\n\n\nA `match_bool_prefix` query analyzes its input and constructs a [`bool` query](/reference/query-languages/query-dsl/query-dsl-bool-query.md) from the terms. Each term except the last is used in a `term` query. The last term is used in a `prefix` query. A `match_bool_prefix` query such as\n\n```console\nGET /_search\n{\n  \"query\": {\n    \"match_bool_prefix\" : {\n      \"message\" : \"quick brown f\"\n    }\n  }\n}\n```\n\nwhere analysis produces the terms `quick`, `brown`, and `f` is similar to the following `bool` query\n\n```console\nGET /_search\n{\n  \"query\": {\n    \"bool\" : {\n      \"should\": [\n        { \"term\": { \"message\": \"quick\" }},\n        { \"term\": { \"message\": \"brown\" }},\n        { \"prefix\": { \"message\": \"f\"}}\n      ]\n    }\n  }\n}\n```\n\nAn important difference between the `match_bool_prefix` query and [`match_phrase_prefix`](/reference/query-languages/query-dsl/query-dsl-match-query-phrase-prefix.md) is that the `match_phrase_prefix` query matches its terms as a phrase, but the `match_bool_prefix` query can match its terms in any position. The example `match_bool_prefix` query above could match a field containing `quick brown fox`, but it could also match `brown fox quick`. It could also match a field containing the term `quick`, the term `brown` and a term starting with `f`, appearing in any position.\n\n## Parameters [_parameters]\n\nBy default, `match_bool_prefix` queries' input text will be analyzed using the analyzer from the queried field\u2019s mapping. A different search analyzer can be configured with the `analyzer` parameter\n\n```console\nGET /_search\n{\n  \"query\": {\n    \"match_bool_prefix\": {\n      \"message\": {\n        \"query\": \"quick brown f\",\n        \"analyzer\": \"keyword\"\n      }\n    }\n  }\n}\n```\n\n`match_bool_prefix` queries support the [`minimum_should_match`](/reference/query-languages/query-dsl/query-dsl-minimum-should-match.md) and `operator` parameters as described for the [`match` query](/reference/query-languages/query-dsl/query-dsl-match-query.md#query-dsl-match-query-boolean), applying the setting to the constructed `bool` query. The number of clauses in the constructed `bool` query will in most cases be the number of terms produced by analysis of the query text.\n\nThe [`fuzziness`](/reference/query-languages/query-dsl/query-dsl-match-query.md#query-dsl-match-query-fuzziness), `prefix_length`, `max_expansions`, `fuzzy_transpositions`, and `fuzzy_rewrite` parameters can be applied to the `term` subqueries constructed for all terms but the final term. They do not have any effect on the prefix query constructed for the final term.",
              "filename": "elasticsearch-main/docs/reference/query-languages/query-dsl/query-dsl-match-bool-prefix-query.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-syntax-reserved.html"
              ],
              "content": "# Reserved keywords [sql-syntax-reserved]\n\nTable with reserved keywords that need to be quoted. Also provide an example to make it more obvious.\n\nThe following table lists all of the keywords that are reserved in Elasticsearch SQL, along with their status in the SQL standard. These reserved keywords must be quoted (using double quotes) in order to be used as an identifier, for example:\n\n```sql\nSELECT \"AS\" FROM index\n```\n\n| **Keyword** | **SQL:2016** | **SQL-92** |\n| --- | --- | --- |\n| `ALL` | reserved | reserved |\n| `AND` | reserved | reserved |\n| `ANY` | reserved | reserved |\n| `AS` | reserved | reserved |\n| `ASC` | reserved | reserved |\n| `BETWEEN` | reserved | reserved |\n| `BY` | reserved | reserved |\n| `CAST` | reserved | reserved |\n| `CATALOG` | reserved | reserved |\n| `CONVERT` | reserved | reserved |\n| `CURRENT_DATE` | reserved | reserved |\n| `CURRENT_TIMESTAMP` | reserved | reserved |\n| `CURRENT_TIME` | reserved | reserved |\n| `DAY` | reserved | reserved |\n| `DAYS` |  |  |\n| `DESC` | reserved | reserved |\n| `DESCRIBE` | reserved | reserved |\n| `DISTINCT` | reserved | reserved |\n| `ESCAPE` | reserved | reserved |\n| `EXISTS` | reserved | reserved |\n| `EXPLAIN` | reserved | reserved |\n| `EXTRACT` | reserved | reserved |\n| `FALSE` | reserved | reserved |\n| `FIRST` | reserved | reserved |\n| `FROM` | reserved | reserved |\n| `FULL` | reserved | reserved |\n| `GROUP` | reserved | reserved |\n| `HAVING` | reserved | reserved |\n| `HOUR` | reserved | reserved |\n| `HOURS` |  |  |\n| `IN` | reserved | reserved |\n| `INNER` | reserved | reserved |\n| `INTERVAL` | reserved | reserved |\n| `IS` | reserved | reserved |\n| `JOIN` | reserved | reserved |\n| `LEFT` | reserved | reserved |\n| `LIKE` | reserved | reserved |\n| `LIMIT` | reserved | reserved |\n| `MATCH` | reserved | reserved |\n| `MINUTE` | reserved | reserved |\n| `MINUTES` |  |  |\n| `MONTH` | reserved | reserved |\n| `NATURAL` | reserved | reserved |\n| `NOT` | reserved | reserved |\n| `NULL` | reserved | reserved |\n| `NULLS` |  |  |\n| `ON` | reserved | reserved |\n| `OR` | reserved | reserved |\n| `ORDER` | reserved | reserved |\n| `OUTER` | reserved | reserved |\n| `RIGHT` | reserved | reserved |\n| `RLIKE` |  |  |\n| `QUERY` |  |  |\n| `SECOND` | reserved | reserved |\n| `SECONDS` |  |  |\n| `SELECT` | reserved | reserved |\n| `SESSION` |  | reserved |\n| `TABLE` | reserved | reserved |\n| `TABLES` |  |  |\n| `THEN` | reserved | reserved |\n| `TO` | reserved | reserved |\n| `TOP` | reserved | reserved |\n| `TRUE` | reserved | reserved |\n| `TYPE` |  |  |\n| `USING` | reserved | reserved |\n| `WHEN` | reserved | reserved |\n| `WHERE` | reserved | reserved |\n| `WITH` | reserved | reserved |\n| `YEAR` | reserved | reserved |\n| `YEARS` |  |  |",
              "filename": "elasticsearch-main/docs/reference/query-languages/sql/sql-syntax-reserved.md"
            }
          ],
          "tool_call_id": "call_Hi9WYxjyMDF4orrx9fTT1dBt",
          "metadata": null,
          "timestamp": "2025-10-03T06:06:51.044735+00:00",
          "part_kind": "tool-return"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "args": "{\"query\":\"hindi text analysis\"}",
          "tool_call_id": "call_zuslAlmbIzlByBRV7eHsVuUz",
          "part_kind": "tool-call"
        }
      ],
      "usage": {
        "input_tokens": 2617,
        "cache_write_tokens": 0,
        "cache_read_tokens": 0,
        "output_tokens": 16,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T06:06:51+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "tool_calls"
      },
      "provider_response_id": "chatcmpl-CMTEJVDBLFUw2AkRVxJoyIB27EKsz",
      "finish_reason": "tool_call"
    },
    {
      "parts": [
        {
          "tool_name": "search",
          "content": [
            {
              "content": "# Text analysis components\n\n% TO-DO: Add links to \"Data analysis basics\"%\n\n:::{note}\nThis section provides detailed **reference information**.\n\nRefer to [the text analysis overview](docs-content://manage-data/data-store/text-analysis.md) in the **Manage data** section for overview and conceptual information.\n:::\n\nThis section contains reference information for text analysis components features, including:\n\n* [Analyzers](/reference/text-analysis/analyzer-reference.md)\n* [Tokenizers](/reference/text-analysis/tokenizer-reference.md)\n* [Token filters](/reference/text-analysis/token-filter-reference.md)\n* [Character filters](/reference/text-analysis/character-filter-reference.md)\n* [Normalizers](/reference/text-analysis/normalizers.md)",
              "filename": "elasticsearch-main/docs/reference/text-analysis/index.md"
            },
            {
              "navigation_title": "Simple",
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-simple-analyzer.html"
              ],
              "content": "# Simple analyzer [analysis-simple-analyzer]\n\n\nThe `simple` analyzer breaks text into tokens at any non-letter character, such as numbers, spaces, hyphens and apostrophes, discards non-letter characters, and changes uppercase to lowercase.\n\n## Example [analysis-simple-analyzer-ex]\n\n```console\nPOST _analyze\n{\n  \"analyzer\": \"simple\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n```\n\nThe `simple` analyzer parses the sentence and produces the following tokens:\n\n```text\n[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]\n```\n\n\n## Definition [analysis-simple-analyzer-definition]\n\nThe `simple` analyzer is defined by one tokenizer:\n\nTokenizer\n:   * [Lowercase Tokenizer](/reference/text-analysis/analysis-lowercase-tokenizer.md)\n\n\n\n## Customize [analysis-simple-analyzer-customize]\n\nTo customize the `simple` analyzer, duplicate it to create the basis for a custom analyzer. This custom analyzer can be modified as required, usually by adding token filters.\n\n```console\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_simple_analyzer\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [                          <1>\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. Add token filters here.",
              "filename": "elasticsearch-main/docs/reference/text-analysis/analysis-simple-analyzer.md"
            },
            {
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis.html"
              ],
              "content": "# Analysis plugins [analysis]\n\nAnalysis plugins extend Elasticsearch by adding new analyzers, tokenizers, token filters, or character filters to Elasticsearch.\n\n\n## Core analysis plugins [_core_analysis_plugins]\n\nThe core analysis plugins are:\n\n[ICU](/reference/elasticsearch-plugins/analysis-icu.md)\n:   Adds extended Unicode support using the [ICU](http://site.icu-project.org/) libraries, including better analysis of Asian languages, Unicode normalization, Unicode-aware case folding, collation support, and transliteration.\n\n[Kuromoji](/reference/elasticsearch-plugins/analysis-kuromoji.md)\n:   Advanced analysis of Japanese using the [Kuromoji analyzer](https://www.atilika.org/).\n\n[Nori](/reference/elasticsearch-plugins/analysis-nori.md)\n:   Morphological analysis of Korean using the Lucene Nori analyzer.\n\n[Phonetic](/reference/elasticsearch-plugins/analysis-phonetic.md)\n:   Analyzes tokens into their phonetic equivalent using Soundex, Metaphone, Caverphone, and other codecs.\n\n[SmartCN](/reference/elasticsearch-plugins/analysis-smartcn.md)\n:   An analyzer for Chinese or mixed Chinese-English text. This analyzer uses probabilistic knowledge to find the optimal word segmentation for Simplified Chinese text. The text is first broken into sentences, then each sentence is segmented into words.\n\n[Stempel](/reference/elasticsearch-plugins/analysis-stempel.md)\n:   Provides high quality stemming for Polish.\n\n[Ukrainian](/reference/elasticsearch-plugins/analysis-ukrainian.md)\n:   Provides stemming for Ukrainian.\n\n\n## Community contributed analysis plugins [_community_contributed_analysis_plugins]\n\nA number of analysis plugins have been contributed by our community:\n\n* [IK Analysis Plugin](https://github.com/medcl/elasticsearch-analysis-ik) (by Medcl)\n* [Pinyin Analysis Plugin](https://github.com/medcl/elasticsearch-analysis-pinyin) (by Medcl)\n* [Vietnamese Analysis Plugin](https://github.com/duydo/elasticsearch-analysis-vietnamese) (by Duy Do)\n* [STConvert Analysis Plugin](https://github.com/medcl/elasticsearch-analysis-stconvert) (by Medcl)",
              "filename": "elasticsearch-main/docs/reference/elasticsearch-plugins/analysis-plugins.md"
            },
            {
              "navigation_title": "Language",
              "mapped_pages": [
                "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html"
              ],
              "content": "# Language analyzers [analysis-lang-analyzer]\n\n\nA set of analyzers aimed at analyzing specific language text. The following types are supported: [`arabic`](#arabic-analyzer), [`armenian`](#armenian-analyzer), [`basque`](#basque-analyzer), [`bengali`](#bengali-analyzer), [`brazilian`](#brazilian-analyzer), [`bulgarian`](#bulgarian-analyzer), [`catalan`](#catalan-analyzer), [`cjk`](#cjk-analyzer), [`czech`](#czech-analyzer), [`danish`](#danish-analyzer), [`dutch`](#dutch-analyzer), [`english`](#english-analyzer), [`estonian`](#estonian-analyzer), [`finnish`](#finnish-analyzer), [`french`](#french-analyzer), [`galician`](#galician-analyzer), [`german`](#german-analyzer), [`greek`](#greek-analyzer), [`hindi`](#hindi-analyzer), [`hungarian`](#hungarian-analyzer), [`indonesian`](#indonesian-analyzer), [`irish`](#irish-analyzer), [`italian`](#italian-analyzer), [`latvian`](#latvian-analyzer), [`lithuanian`](#lithuanian-analyzer), [`norwegian`](#norwegian-analyzer), [`persian`](#persian-analyzer), [`portuguese`](#portuguese-analyzer), [`romanian`](#romanian-analyzer), [`russian`](#russian-analyzer), [`serbian`](#serbian-analyzer), [`sorani`](#sorani-analyzer), [`spanish`](#spanish-analyzer), [`swedish`](#swedish-analyzer), [`turkish`](#turkish-analyzer), [`thai`](#thai-analyzer).\n\n## Configuring language analyzers [_configuring_language_analyzers]\n\n### Stopwords [_stopwords]\n\nAll analyzers support setting custom `stopwords` either internally in the config, or by using an external stopwords file by setting `stopwords_path`. Check [Stop Analyzer](/reference/text-analysis/analysis-stop-analyzer.md) for more details.\n\n\n### Excluding words from stemming [_excluding_words_from_stemming]\n\nThe `stem_exclusion` parameter allows you to specify an array of lowercase words that should not be stemmed. Internally, this functionality is implemented by adding the [`keyword_marker` token filter](/reference/text-analysis/analysis-keyword-marker-tokenfilter.md) with the `keywords` set to the value of the `stem_exclusion` parameter.\n\nThe following analyzers support setting custom `stem_exclusion` list: `arabic`, `armenian`, `basque`, `bengali`, `bulgarian`, `catalan`, `czech`, `dutch`, `english`, `finnish`, `french`, `galician`, `german`, `hindi`, `hungarian`, `indonesian`, `irish`, `italian`, `latvian`, `lithuanian`, `norwegian`, `portuguese`, `romanian`, `russian`, `serbian`, `sorani`, `spanish`, `swedish`, `turkish`.\n\n\n\n## Reimplementing language analyzers [_reimplementing_language_analyzers]\n\nThe built-in language analyzers can be reimplemented as `custom` analyzers (as described below) in order to customize their behaviour.\n\n::::{note}\nIf you do not intend to exclude words from being stemmed (the equivalent of the `stem_exclusion` parameter above), then you should remove the `keyword_marker` token filter from the custom analyzer configuration.\n::::\n\n\n### `arabic` analyzer [arabic-analyzer]\n\nThe `arabic` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /arabic_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"arabic_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_arabic_\" <1>\n        },\n        \"arabic_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u0645\u062b\u0627\u0644\"] <2>\n        },\n        \"arabic_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"arabic\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_arabic\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"arabic_stop\",\n            \"arabic_normalization\",\n            \"arabic_keywords\",\n            \"arabic_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `armenian` analyzer [armenian-analyzer]\n\nThe `armenian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /armenian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"armenian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_armenian_\" <1>\n        },\n        \"armenian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u0585\u0580\u056b\u0576\u0561\u056f\"] <2>\n        },\n        \"armenian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"armenian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_armenian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"armenian_stop\",\n            \"armenian_keywords\",\n            \"armenian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `basque` analyzer [basque-analyzer]\n\nThe `basque` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /basque_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"basque_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_basque_\" <1>\n        },\n        \"basque_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Adibidez\"] <2>\n        },\n        \"basque_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"basque\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_basque\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"basque_stop\",\n            \"basque_keywords\",\n            \"basque_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `bengali` analyzer [bengali-analyzer]\n\nThe `bengali` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /bengali_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"bengali_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_bengali_\" <1>\n        },\n        \"bengali_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u0989\u09a6\u09be\u09b9\u09b0\u09a3\"] <2>\n        },\n        \"bengali_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"bengali\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_bengali\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"bengali_keywords\",\n            \"indic_normalization\",\n            \"bengali_normalization\",\n            \"bengali_stop\",\n            \"bengali_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `brazilian` analyzer [brazilian-analyzer]\n\nThe `brazilian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /brazilian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"brazilian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_brazilian_\" <1>\n        },\n        \"brazilian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplo\"] <2>\n        },\n        \"brazilian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"brazilian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_brazilian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"brazilian_stop\",\n            \"brazilian_keywords\",\n            \"brazilian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `bulgarian` analyzer [bulgarian-analyzer]\n\nThe `bulgarian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /bulgarian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"bulgarian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_bulgarian_\" <1>\n        },\n        \"bulgarian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u043f\u0440\u0438\u043c\u0435\u0440\"] <2>\n        },\n        \"bulgarian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"bulgarian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_bulgarian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"bulgarian_stop\",\n            \"bulgarian_keywords\",\n            \"bulgarian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `catalan` analyzer [catalan-analyzer]\n\nThe `catalan` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /catalan_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"catalan_elision\": {\n          \"type\":       \"elision\",\n          \"articles\":   [ \"d\", \"l\", \"m\", \"n\", \"s\", \"t\"],\n          \"articles_case\": true\n        },\n        \"catalan_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_catalan_\" <1>\n        },\n        \"catalan_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"example\"] <2>\n        },\n        \"catalan_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"catalan\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_catalan\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"catalan_elision\",\n            \"lowercase\",\n            \"catalan_stop\",\n            \"catalan_keywords\",\n            \"catalan_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `cjk` analyzer [cjk-analyzer]\n\n::::{note}\nYou may find that `icu_analyzer` in the ICU analysis plugin works better for CJK text than the `cjk` analyzer. Experiment with your text and queries.\n::::\n\n\nThe `cjk` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /cjk_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  [ <1>\n            \"a\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\",\n            \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\",\n            \"or\", \"s\", \"such\", \"t\", \"that\", \"the\", \"their\", \"then\",\n            \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\",\n            \"with\", \"www\"\n          ]\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_cjk\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"cjk_width\",\n            \"lowercase\",\n            \"cjk_bigram\",\n            \"english_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters. The default stop words are **almost** the same as the `_english_` set, but not exactly the same.\n\n\n\n### `czech` analyzer [czech-analyzer]\n\nThe `czech` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /czech_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"czech_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_czech_\" <1>\n        },\n        \"czech_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"p\u0159\u00edklad\"] <2>\n        },\n        \"czech_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"czech\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_czech\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"czech_stop\",\n            \"czech_keywords\",\n            \"czech_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `danish` analyzer [danish-analyzer]\n\nThe `danish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /danish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"danish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_danish_\" <1>\n        },\n        \"danish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"eksempel\"] <2>\n        },\n        \"danish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"danish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_danish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"danish_stop\",\n            \"danish_keywords\",\n            \"danish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `dutch` analyzer [dutch-analyzer]\n\nThe `dutch` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /dutch_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"dutch_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_dutch_\" <1>\n        },\n        \"dutch_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"voorbeeld\"] <2>\n        },\n        \"dutch_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"dutch\"\n        },\n        \"dutch_override\": {\n          \"type\":       \"stemmer_override\",\n          \"rules\": [\n            \"fiets=>fiets\",\n            \"bromfiets=>bromfiets\",\n            \"ei=>eier\",\n            \"kind=>kinder\"\n          ]\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_dutch\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"dutch_stop\",\n            \"dutch_keywords\",\n            \"dutch_override\",\n            \"dutch_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `english` analyzer [english-analyzer]\n\nThe `english` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /english_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_english_\" <1>\n        },\n        \"english_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"example\"] <2>\n        },\n        \"english_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"english\"\n        },\n        \"english_possessive_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"possessive_english\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_english\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"english_possessive_stemmer\",\n            \"lowercase\",\n            \"english_stop\",\n            \"english_keywords\",\n            \"english_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `estonian` analyzer [estonian-analyzer]\n\nThe `estonian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /estonian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"estonian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_estonian_\" <1>\n        },\n        \"estonian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"n\u00e4ide\"] <2>\n        },\n        \"estonian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"estonian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_estonian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"estonian_stop\",\n            \"estonian_keywords\",\n            \"estonian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `finnish` analyzer [finnish-analyzer]\n\nThe `finnish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /finnish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"finnish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_finnish_\" <1>\n        },\n        \"finnish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"esimerkki\"] <2>\n        },\n        \"finnish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"finnish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_finnish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"finnish_stop\",\n            \"finnish_keywords\",\n            \"finnish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `french` analyzer [french-analyzer]\n\nThe `french` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /french_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"french_elision\": {\n          \"type\":         \"elision\",\n          \"articles_case\": true,\n          \"articles\": [\n              \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\",\n              \"j\", \"d\", \"c\", \"jusqu\", \"quoiqu\",\n              \"lorsqu\", \"puisqu\"\n            ]\n        },\n        \"french_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_french_\" <1>\n        },\n        \"french_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Example\"] <2>\n        },\n        \"french_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_french\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_french\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"french_elision\",\n            \"lowercase\",\n            \"french_stop\",\n            \"french_keywords\",\n            \"french_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `galician` analyzer [galician-analyzer]\n\nThe `galician` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /galician_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"galician_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_galician_\" <1>\n        },\n        \"galician_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplo\"] <2>\n        },\n        \"galician_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"galician\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_galician\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"galician_stop\",\n            \"galician_keywords\",\n            \"galician_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `german` analyzer [german-analyzer]\n\nThe `german` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /german_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"german_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_german_\" <1>\n        },\n        \"german_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"Beispiel\"] <2>\n        },\n        \"german_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_german\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_german\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"german_stop\",\n            \"german_keywords\",\n            \"german_normalization\",\n            \"german_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `greek` analyzer [greek-analyzer]\n\nThe `greek` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /greek_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"greek_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_greek_\" <1>\n        },\n        \"greek_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"greek\"\n        },\n        \"greek_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u03c0\u03b1\u03c1\u03ac\u03b4\u03b5\u03b9\u03b3\u03bc\u03b1\"] <2>\n        },\n        \"greek_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"greek\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_greek\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"greek_lowercase\",\n            \"greek_stop\",\n            \"greek_keywords\",\n            \"greek_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `hindi` analyzer [hindi-analyzer]\n\nThe `hindi` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /hindi_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"hindi_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_hindi_\" <1>\n        },\n        \"hindi_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u0909\u0926\u093e\u0939\u0930\u0923\"] <2>\n        },\n        \"hindi_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"hindi\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_hindi\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"hindi_keywords\",\n            \"indic_normalization\",\n            \"hindi_normalization\",\n            \"hindi_stop\",\n            \"hindi_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `hungarian` analyzer [hungarian-analyzer]\n\nThe `hungarian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /hungarian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"hungarian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_hungarian_\" <1>\n        },\n        \"hungarian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"p\u00e9lda\"] <2>\n        },\n        \"hungarian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"hungarian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_hungarian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"hungarian_stop\",\n            \"hungarian_keywords\",\n            \"hungarian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `indonesian` analyzer [indonesian-analyzer]\n\nThe `indonesian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /indonesian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"indonesian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_indonesian_\" <1>\n        },\n        \"indonesian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"contoh\"] <2>\n        },\n        \"indonesian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"indonesian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_indonesian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"indonesian_stop\",\n            \"indonesian_keywords\",\n            \"indonesian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `irish` analyzer [irish-analyzer]\n\nThe `irish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /irish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"irish_hyphenation\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  [ \"h\", \"n\", \"t\" ],\n          \"ignore_case\": true\n        },\n        \"irish_elision\": {\n          \"type\":       \"elision\",\n          \"articles\":   [ \"d\", \"m\", \"b\" ],\n          \"articles_case\": true\n        },\n        \"irish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_irish_\" <1>\n        },\n        \"irish_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"irish\"\n        },\n        \"irish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"sampla\"] <2>\n        },\n        \"irish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"irish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_irish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"irish_hyphenation\",\n            \"irish_elision\",\n            \"irish_lowercase\",\n            \"irish_stop\",\n            \"irish_keywords\",\n            \"irish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `italian` analyzer [italian-analyzer]\n\nThe `italian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /italian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"italian_elision\": {\n          \"type\": \"elision\",\n          \"articles\": [\n                \"c\", \"l\", \"all\", \"dall\", \"dell\",\n                \"nell\", \"sull\", \"coll\", \"pell\",\n                \"gl\", \"agl\", \"dagl\", \"degl\", \"negl\",\n                \"sugl\", \"un\", \"m\", \"t\", \"s\", \"v\", \"d\"\n          ],\n          \"articles_case\": true\n        },\n        \"italian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_italian_\" <1>\n        },\n        \"italian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"esempio\"] <2>\n        },\n        \"italian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_italian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_italian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"italian_elision\",\n            \"lowercase\",\n            \"italian_stop\",\n            \"italian_keywords\",\n            \"italian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `latvian` analyzer [latvian-analyzer]\n\nThe `latvian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /latvian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"latvian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_latvian_\" <1>\n        },\n        \"latvian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"piem\u0113rs\"] <2>\n        },\n        \"latvian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"latvian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_latvian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"latvian_stop\",\n            \"latvian_keywords\",\n            \"latvian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `lithuanian` analyzer [lithuanian-analyzer]\n\nThe `lithuanian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /lithuanian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"lithuanian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_lithuanian_\" <1>\n        },\n        \"lithuanian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"pavyzdys\"] <2>\n        },\n        \"lithuanian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"lithuanian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_lithuanian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"lithuanian_stop\",\n            \"lithuanian_keywords\",\n            \"lithuanian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `norwegian` analyzer [norwegian-analyzer]\n\nThe `norwegian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /norwegian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"norwegian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_norwegian_\" <1>\n        },\n        \"norwegian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"eksempel\"] <2>\n        },\n        \"norwegian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"norwegian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_norwegian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"norwegian_stop\",\n            \"norwegian_keywords\",\n            \"norwegian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `persian` analyzer [persian-analyzer]\n\nThe `persian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /persian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"char_filter\": {\n        \"zero_width_spaces\": {\n            \"type\":       \"mapping\",\n            \"mappings\": [ \"\\\\u200C=>\\\\u0020\"] <1>\n        }\n      },\n      \"filter\": {\n        \"persian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_persian_\" <2>\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_persian\": {\n          \"tokenizer\":     \"standard\",\n          \"char_filter\": [ \"zero_width_spaces\" ],\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"arabic_normalization\",\n            \"persian_normalization\",\n            \"persian_stop\",\n            \"persian_stem\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. Replaces zero-width non-joiners with an ASCII space.\n2. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n\n\n\n### `portuguese` analyzer [portuguese-analyzer]\n\nThe `portuguese` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /portuguese_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"portuguese_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_portuguese_\" <1>\n        },\n        \"portuguese_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplo\"] <2>\n        },\n        \"portuguese_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_portuguese\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_portuguese\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"portuguese_stop\",\n            \"portuguese_keywords\",\n            \"portuguese_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `romanian` analyzer [romanian-analyzer]\n\nThe `romanian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /romanian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"romanian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_romanian_\" <1>\n        },\n        \"romanian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exemplu\"] <2>\n        },\n        \"romanian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"romanian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_romanian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"romanian_stop\",\n            \"romanian_keywords\",\n            \"romanian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `russian` analyzer [russian-analyzer]\n\nThe `russian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /russian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"russian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_russian_\" <1>\n        },\n        \"russian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u043f\u0440\u0438\u043c\u0435\u0440\"] <2>\n        },\n        \"russian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"russian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_russian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"russian_stop\",\n            \"russian_keywords\",\n            \"russian_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `serbian` analyzer [serbian-analyzer]\n\nThe `serbian` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /serbian_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"serbian_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_serbian_\" <1>\n        },\n        \"serbian_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u043f\u0440\u0438\u043c\u0435\u0440\"] <2>\n        },\n        \"serbian_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"serbian\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_serbian\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"serbian_stop\",\n            \"serbian_keywords\",\n            \"serbian_stemmer\",\n            \"serbian_normalization\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `sorani` analyzer [sorani-analyzer]\n\nThe `sorani` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /sorani_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"sorani_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_sorani_\" <1>\n        },\n        \"sorani_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"m\u00eenak\"] <2>\n        },\n        \"sorani_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"sorani\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_sorani\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"sorani_normalization\",\n            \"lowercase\",\n            \"decimal_digit\",\n            \"sorani_stop\",\n            \"sorani_keywords\",\n            \"sorani_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `spanish` analyzer [spanish-analyzer]\n\nThe `spanish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /spanish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"spanish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_spanish_\" <1>\n        },\n        \"spanish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"ejemplo\"] <2>\n        },\n        \"spanish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"light_spanish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_spanish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"spanish_stop\",\n            \"spanish_keywords\",\n            \"spanish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `swedish` analyzer [swedish-analyzer]\n\nThe `swedish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /swedish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"swedish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_swedish_\" <1>\n        },\n        \"swedish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"exempel\"] <2>\n        },\n        \"swedish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"swedish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_swedish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"swedish_stop\",\n            \"swedish_keywords\",\n            \"swedish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `turkish` analyzer [turkish-analyzer]\n\nThe `turkish` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /turkish_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"turkish_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_turkish_\" <1>\n        },\n        \"turkish_lowercase\": {\n          \"type\":       \"lowercase\",\n          \"language\":   \"turkish\"\n        },\n        \"turkish_keywords\": {\n          \"type\":       \"keyword_marker\",\n          \"keywords\":   [\"\u00f6rnek\"] <2>\n        },\n        \"turkish_stemmer\": {\n          \"type\":       \"stemmer\",\n          \"language\":   \"turkish\"\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_turkish\": {\n          \"tokenizer\":  \"standard\",\n          \"filter\": [\n            \"apostrophe\",\n            \"turkish_lowercase\",\n            \"turkish_stop\",\n            \"turkish_keywords\",\n            \"turkish_stemmer\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.\n2. This filter should be removed unless there are words which should be excluded from stemming.\n\n\n\n### `thai` analyzer [thai-analyzer]\n\nThe `thai` analyzer could be reimplemented as a `custom` analyzer as follows:\n\n```console\nPUT /thai_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"thai_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_thai_\" <1>\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_thai\": {\n          \"tokenizer\":  \"thai\",\n          \"filter\": [\n            \"lowercase\",\n            \"decimal_digit\",\n            \"thai_stop\"\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\n1. The default stopwords can be overridden with the `stopwords` or `stopwords_path` parameters.",
              "filename": "elasticsearch-main/docs/reference/text-analysis/analysis-lang-analyzer.md"
            },
            {
              "content": "# Reference",
              "filename": "elasticsearch-main/docs/reference/index.md"
            }
          ],
          "tool_call_id": "call_zuslAlmbIzlByBRV7eHsVuUz",
          "metadata": null,
          "timestamp": "2025-10-03T06:06:52.782660+00:00",
          "part_kind": "tool-return"
        }
      ],
      "instructions": "You are a helpful assistant that answers questions about documentation.  \n\nUse the search tool to find relevant information from the repository before answering questions.  \n\nIf you can find specific information through search, use it to provide accurate answers.\n\nAlways include references by citing the filename of the source material you used.\nReplace it with the full path to the GitHub repository:\n\"https://github.com/elastic/elasticsearch/blob/main/\"\nFormat: [LINK TITLE](FULL_GITHUB_LINK)\n\n\nIf the search doesn't return relevant results, let the user know and provide general guidance.",
      "kind": "request"
    },
    {
      "parts": [
        {
          "content": "The `hindi_keywords` filter in Elasticsearch serves as a part of the Hindi text analysis process. Specifically, it is a **keyword marker** filter that identifies specific tokens that should not be modified during text processing, particularly by stemming or other normalization processes. \n\nIn the context of the Hindi analyzer, `hindi_keywords` is employed to specify a list of words (or tokens) that are essential to retain in their original form. This is particularly useful for maintaining the integrity of important terms in search queries, ensuring that these significant tokens do not get altered or discarded during analysis, which could impact the accuracy of search results.\n\n### Example of the Hindi Analyzer Configuration:\n```json\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"hindi_keywords\": {\n          \"type\": \"keyword_marker\",\n          \"keywords\": [\"\u0909\u0926\u093e\u0939\u0930\u0923\"]  // Example of a keyword that won't be altered\n        }\n      },\n      \"analyzer\": {\n        \"hindi_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"hindi_keywords\",\n            \"hindi_stemmer\"  // This is another component of the analysis\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\nThis configuration illustrates how the `hindi_keywords` filter is integrated into the analyzer, ensuring that specified keywords remain unchanged throughout the text analysis process.\n\nFor more detailed information about the `hindi` analyzer and its components, you can refer to the official Elasticsearch documentation on [Language Analyzers](https://github.com/elastic/elasticsearch/blob/main/docs/reference/text-analysis/analysis-lang-analyzer.md).",
          "id": null,
          "part_kind": "text"
        }
      ],
      "usage": {
        "input_tokens": 16445,
        "cache_write_tokens": 0,
        "cache_read_tokens": 2560,
        "output_tokens": 341,
        "input_audio_tokens": 0,
        "cache_audio_read_tokens": 0,
        "output_audio_tokens": 0,
        "details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        }
      },
      "model_name": "gpt-4o-mini-2024-07-18",
      "timestamp": "2025-10-03T06:06:53+00:00",
      "kind": "response",
      "provider_name": "openai",
      "provider_details": {
        "finish_reason": "stop"
      },
      "provider_response_id": "chatcmpl-CMTELZhzpVMn1XDAxiuwdssBDCQG5",
      "finish_reason": "stop"
    }
  ],
  "source": "ai-generated"
}